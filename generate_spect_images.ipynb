{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corona Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-ad533eb0a369>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "#Data visualization\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Audio Analysis\n",
    "import glob\n",
    "import IPython\n",
    "import librosa\n",
    "import librosa.display\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "#path\n",
    "import os\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1397 entries, 0 to 1396\n",
      "Data columns (total 37 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   USER_ID                 1397 non-null   object \n",
      " 1   COUNTRY                 1397 non-null   object \n",
      " 2   AGE                     1397 non-null   int64  \n",
      " 3   COVID_STATUS            1396 non-null   object \n",
      " 4   ENGLISH_PROFICIENCY     1397 non-null   object \n",
      " 5   GENDER                  1397 non-null   object \n",
      " 6   COUNTY_RO_STATE         1397 non-null   object \n",
      " 7   CITY_LOCALITY           1228 non-null   object \n",
      " 8   Diabetes                1397 non-null   int64  \n",
      " 9   Asthma                  1397 non-null   int64  \n",
      " 10  Smoker                  1397 non-null   int64  \n",
      " 11  Hypertension            1397 non-null   int64  \n",
      " 12  Fever                   1397 non-null   int64  \n",
      " 13  Returning_User          1397 non-null   int64  \n",
      " 14  Using_Mask              1397 non-null   int64  \n",
      " 15  Cold                    1397 non-null   int64  \n",
      " 16  Caugh                   1397 non-null   int64  \n",
      " 17  Muscle_Pain             1397 non-null   int64  \n",
      " 18  loss_of_smell           1397 non-null   int64  \n",
      " 19  Sore_Throat             1397 non-null   int64  \n",
      " 20  Fatigue                 1397 non-null   int64  \n",
      " 21  Breathing_Difficulties  1397 non-null   int64  \n",
      " 22  Chronic_Lung_Disease    1397 non-null   int64  \n",
      " 23  Ischemic_Heart_Disease  1397 non-null   int64  \n",
      " 24  Pneumonia               1397 non-null   int64  \n",
      " 25  COVID_test_status       1355 non-null   float64\n",
      " 26  Diarrheoa               1397 non-null   int64  \n",
      " 27  DATES                   1397 non-null   int64  \n",
      " 28  breathing-deep          1396 non-null   object \n",
      " 29  breathing-shallow       1396 non-null   object \n",
      " 30  cough-heavy             1396 non-null   object \n",
      " 31  cough-shallow           1395 non-null   object \n",
      " 32  counting-fast           1397 non-null   object \n",
      " 33  counting-normal         1397 non-null   object \n",
      " 34  vowel-a                 1396 non-null   object \n",
      " 35  vowel-e                 1396 non-null   object \n",
      " 36  vowel-o                 1395 non-null   object \n",
      "dtypes: float64(1), int64(20), object(16)\n",
      "memory usage: 403.9+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, (1397, 37))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import meta data\n",
    "\n",
    "df_meta = pd.read_csv('./CoronaHack-Respiratory-Sound-Dataset/Corona-Hack-Respiratory-Sound-Metadata.csv')\n",
    "df_meta.info(), df_meta.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\paulg\\.conda\\envs\\corona\\lib\\site-packages\\pandas\\core\\indexing.py:1745: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(ilocs[0], value)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(56, 1340)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Use path info from csv file to load data \n",
    "\n",
    "#split COVID STATUS to get labels\n",
    "df_meta['split'] = df_meta['COVID_STATUS'].str.split('_').str.get(0)\n",
    "#Check for NA\n",
    "df_meta.loc[:,'counting-normal'].isna().sum()\n",
    "df_meta.loc[:,'split'].value_counts()\n",
    "\n",
    "#Generate a dict to categorize split column\n",
    "cat_dict = {'healthy':0,'no':0,'resp':0,'recovered':0,'positive':1}\n",
    "\n",
    "#map cat_dict to split column \n",
    "df_meta.loc[:,'split'] =  df_meta.loc[:,'split'].map(cat_dict)\n",
    "df_meta2 = df_meta.dropna(subset=['split'])\n",
    "df_meta2.loc[:,'split'] = df_meta2.loc[:,'split'].astype('int32')\n",
    "\n",
    "\n",
    "#Extract positive USER ID\n",
    "df_meta_positives = df_meta[df_meta['split'] == 1]\n",
    "df_meta_negatives = df_meta[df_meta['split'] == 0]\n",
    "\n",
    "positives = list(df_meta_positives['USER_ID'])\n",
    "negatives = list(df_meta_negatives['USER_ID'])\n",
    "len(positives),len(negatives)\n",
    "#positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>USER_ID</th>\n",
       "      <th>COUNTRY</th>\n",
       "      <th>AGE</th>\n",
       "      <th>COVID_STATUS</th>\n",
       "      <th>ENGLISH_PROFICIENCY</th>\n",
       "      <th>GENDER</th>\n",
       "      <th>COUNTY_RO_STATE</th>\n",
       "      <th>CITY_LOCALITY</th>\n",
       "      <th>Diabetes</th>\n",
       "      <th>Asthma</th>\n",
       "      <th>...</th>\n",
       "      <th>breathing-deep</th>\n",
       "      <th>breathing-shallow</th>\n",
       "      <th>cough-heavy</th>\n",
       "      <th>cough-shallow</th>\n",
       "      <th>counting-fast</th>\n",
       "      <th>counting-normal</th>\n",
       "      <th>vowel-a</th>\n",
       "      <th>vowel-e</th>\n",
       "      <th>vowel-o</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vK2bLRNzllXNeyOMudnNSL5cfpG2</td>\n",
       "      <td>India</td>\n",
       "      <td>24</td>\n",
       "      <td>healthy</td>\n",
       "      <td>Y</td>\n",
       "      <td>M</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>/data/train/20200413/vK2bLRNzllXNeyOMudnNSL5cf...</td>\n",
       "      <td>/data/train/20200413/vK2bLRNzllXNeyOMudnNSL5cf...</td>\n",
       "      <td>/data/train/20200413/vK2bLRNzllXNeyOMudnNSL5cf...</td>\n",
       "      <td>/data/train/20200413/vK2bLRNzllXNeyOMudnNSL5cf...</td>\n",
       "      <td>/data/train/20200413/vK2bLRNzllXNeyOMudnNSL5cf...</td>\n",
       "      <td>/data/train/20200413/vK2bLRNzllXNeyOMudnNSL5cf...</td>\n",
       "      <td>/data/train/20200413/vK2bLRNzllXNeyOMudnNSL5cf...</td>\n",
       "      <td>/data/train/20200413/vK2bLRNzllXNeyOMudnNSL5cf...</td>\n",
       "      <td>/data/train/20200413/vK2bLRNzllXNeyOMudnNSL5cf...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bjA2KpSxneNskrLBeqi4bqoTDQl2</td>\n",
       "      <td>India</td>\n",
       "      <td>72</td>\n",
       "      <td>healthy</td>\n",
       "      <td>Y</td>\n",
       "      <td>M</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>Thane</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>/data/train/20200413/bjA2KpSxneNskrLBeqi4bqoTD...</td>\n",
       "      <td>/data/train/20200413/bjA2KpSxneNskrLBeqi4bqoTD...</td>\n",
       "      <td>/data/train/20200413/bjA2KpSxneNskrLBeqi4bqoTD...</td>\n",
       "      <td>/data/train/20200413/bjA2KpSxneNskrLBeqi4bqoTD...</td>\n",
       "      <td>/data/train/20200413/bjA2KpSxneNskrLBeqi4bqoTD...</td>\n",
       "      <td>/data/train/20200413/bjA2KpSxneNskrLBeqi4bqoTD...</td>\n",
       "      <td>/data/train/20200413/bjA2KpSxneNskrLBeqi4bqoTD...</td>\n",
       "      <td>/data/train/20200413/bjA2KpSxneNskrLBeqi4bqoTD...</td>\n",
       "      <td>/data/train/20200413/bjA2KpSxneNskrLBeqi4bqoTD...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FSzobvJqOXf0rI6X05cHqOiU9Mu2</td>\n",
       "      <td>India</td>\n",
       "      <td>54</td>\n",
       "      <td>healthy</td>\n",
       "      <td>Y</td>\n",
       "      <td>M</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>Thane West</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>/data/train/20200413/FSzobvJqOXf0rI6X05cHqOiU9...</td>\n",
       "      <td>/data/train/20200413/FSzobvJqOXf0rI6X05cHqOiU9...</td>\n",
       "      <td>/data/train/20200413/FSzobvJqOXf0rI6X05cHqOiU9...</td>\n",
       "      <td>/data/train/20200413/FSzobvJqOXf0rI6X05cHqOiU9...</td>\n",
       "      <td>/data/train/20200413/FSzobvJqOXf0rI6X05cHqOiU9...</td>\n",
       "      <td>/data/train/20200413/FSzobvJqOXf0rI6X05cHqOiU9...</td>\n",
       "      <td>/data/train/20200413/FSzobvJqOXf0rI6X05cHqOiU9...</td>\n",
       "      <td>/data/train/20200413/FSzobvJqOXf0rI6X05cHqOiU9...</td>\n",
       "      <td>/data/train/20200413/FSzobvJqOXf0rI6X05cHqOiU9...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EqDWckxbsETyHUeBLQ8jLtxlhir2</td>\n",
       "      <td>India</td>\n",
       "      <td>31</td>\n",
       "      <td>healthy</td>\n",
       "      <td>Y</td>\n",
       "      <td>M</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>/data/train/20200413/EqDWckxbsETyHUeBLQ8jLtxlh...</td>\n",
       "      <td>/data/train/20200413/EqDWckxbsETyHUeBLQ8jLtxlh...</td>\n",
       "      <td>/data/train/20200413/EqDWckxbsETyHUeBLQ8jLtxlh...</td>\n",
       "      <td>/data/train/20200413/EqDWckxbsETyHUeBLQ8jLtxlh...</td>\n",
       "      <td>/data/train/20200413/EqDWckxbsETyHUeBLQ8jLtxlh...</td>\n",
       "      <td>/data/train/20200413/EqDWckxbsETyHUeBLQ8jLtxlh...</td>\n",
       "      <td>/data/train/20200413/EqDWckxbsETyHUeBLQ8jLtxlh...</td>\n",
       "      <td>/data/train/20200413/EqDWckxbsETyHUeBLQ8jLtxlh...</td>\n",
       "      <td>/data/train/20200413/EqDWckxbsETyHUeBLQ8jLtxlh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FGRDO4IBbAejR0WHD5YbkXTCasg2</td>\n",
       "      <td>India</td>\n",
       "      <td>26</td>\n",
       "      <td>healthy</td>\n",
       "      <td>Y</td>\n",
       "      <td>M</td>\n",
       "      <td>Haryana</td>\n",
       "      <td>gurgaon</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>/data/train/20200413/FGRDO4IBbAejR0WHD5YbkXTCa...</td>\n",
       "      <td>/data/train/20200413/FGRDO4IBbAejR0WHD5YbkXTCa...</td>\n",
       "      <td>/data/train/20200413/FGRDO4IBbAejR0WHD5YbkXTCa...</td>\n",
       "      <td>/data/train/20200413/FGRDO4IBbAejR0WHD5YbkXTCa...</td>\n",
       "      <td>/data/train/20200413/FGRDO4IBbAejR0WHD5YbkXTCa...</td>\n",
       "      <td>/data/train/20200413/FGRDO4IBbAejR0WHD5YbkXTCa...</td>\n",
       "      <td>/data/train/20200413/FGRDO4IBbAejR0WHD5YbkXTCa...</td>\n",
       "      <td>/data/train/20200413/FGRDO4IBbAejR0WHD5YbkXTCa...</td>\n",
       "      <td>/data/train/20200413/FGRDO4IBbAejR0WHD5YbkXTCa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        USER_ID COUNTRY  AGE COVID_STATUS ENGLISH_PROFICIENCY  \\\n",
       "0  vK2bLRNzllXNeyOMudnNSL5cfpG2   India   24      healthy                   Y   \n",
       "1  bjA2KpSxneNskrLBeqi4bqoTDQl2   India   72      healthy                   Y   \n",
       "2  FSzobvJqOXf0rI6X05cHqOiU9Mu2   India   54      healthy                   Y   \n",
       "3  EqDWckxbsETyHUeBLQ8jLtxlhir2   India   31      healthy                   Y   \n",
       "4  FGRDO4IBbAejR0WHD5YbkXTCasg2   India   26      healthy                   Y   \n",
       "\n",
       "  GENDER COUNTY_RO_STATE CITY_LOCALITY  Diabetes  Asthma  ...  \\\n",
       "0      M       Karnataka     Bangalore         0       0  ...   \n",
       "1      M     Maharashtra         Thane         0       0  ...   \n",
       "2      M     Maharashtra    Thane West         0       0  ...   \n",
       "3      M       Karnataka     Bangalore         0       0  ...   \n",
       "4      M         Haryana       gurgaon         0       0  ...   \n",
       "\n",
       "                                      breathing-deep  \\\n",
       "0  /data/train/20200413/vK2bLRNzllXNeyOMudnNSL5cf...   \n",
       "1  /data/train/20200413/bjA2KpSxneNskrLBeqi4bqoTD...   \n",
       "2  /data/train/20200413/FSzobvJqOXf0rI6X05cHqOiU9...   \n",
       "3  /data/train/20200413/EqDWckxbsETyHUeBLQ8jLtxlh...   \n",
       "4  /data/train/20200413/FGRDO4IBbAejR0WHD5YbkXTCa...   \n",
       "\n",
       "                                   breathing-shallow  \\\n",
       "0  /data/train/20200413/vK2bLRNzllXNeyOMudnNSL5cf...   \n",
       "1  /data/train/20200413/bjA2KpSxneNskrLBeqi4bqoTD...   \n",
       "2  /data/train/20200413/FSzobvJqOXf0rI6X05cHqOiU9...   \n",
       "3  /data/train/20200413/EqDWckxbsETyHUeBLQ8jLtxlh...   \n",
       "4  /data/train/20200413/FGRDO4IBbAejR0WHD5YbkXTCa...   \n",
       "\n",
       "                                         cough-heavy  \\\n",
       "0  /data/train/20200413/vK2bLRNzllXNeyOMudnNSL5cf...   \n",
       "1  /data/train/20200413/bjA2KpSxneNskrLBeqi4bqoTD...   \n",
       "2  /data/train/20200413/FSzobvJqOXf0rI6X05cHqOiU9...   \n",
       "3  /data/train/20200413/EqDWckxbsETyHUeBLQ8jLtxlh...   \n",
       "4  /data/train/20200413/FGRDO4IBbAejR0WHD5YbkXTCa...   \n",
       "\n",
       "                                       cough-shallow  \\\n",
       "0  /data/train/20200413/vK2bLRNzllXNeyOMudnNSL5cf...   \n",
       "1  /data/train/20200413/bjA2KpSxneNskrLBeqi4bqoTD...   \n",
       "2  /data/train/20200413/FSzobvJqOXf0rI6X05cHqOiU9...   \n",
       "3  /data/train/20200413/EqDWckxbsETyHUeBLQ8jLtxlh...   \n",
       "4  /data/train/20200413/FGRDO4IBbAejR0WHD5YbkXTCa...   \n",
       "\n",
       "                                       counting-fast  \\\n",
       "0  /data/train/20200413/vK2bLRNzllXNeyOMudnNSL5cf...   \n",
       "1  /data/train/20200413/bjA2KpSxneNskrLBeqi4bqoTD...   \n",
       "2  /data/train/20200413/FSzobvJqOXf0rI6X05cHqOiU9...   \n",
       "3  /data/train/20200413/EqDWckxbsETyHUeBLQ8jLtxlh...   \n",
       "4  /data/train/20200413/FGRDO4IBbAejR0WHD5YbkXTCa...   \n",
       "\n",
       "                                     counting-normal  \\\n",
       "0  /data/train/20200413/vK2bLRNzllXNeyOMudnNSL5cf...   \n",
       "1  /data/train/20200413/bjA2KpSxneNskrLBeqi4bqoTD...   \n",
       "2  /data/train/20200413/FSzobvJqOXf0rI6X05cHqOiU9...   \n",
       "3  /data/train/20200413/EqDWckxbsETyHUeBLQ8jLtxlh...   \n",
       "4  /data/train/20200413/FGRDO4IBbAejR0WHD5YbkXTCa...   \n",
       "\n",
       "                                             vowel-a  \\\n",
       "0  /data/train/20200413/vK2bLRNzllXNeyOMudnNSL5cf...   \n",
       "1  /data/train/20200413/bjA2KpSxneNskrLBeqi4bqoTD...   \n",
       "2  /data/train/20200413/FSzobvJqOXf0rI6X05cHqOiU9...   \n",
       "3  /data/train/20200413/EqDWckxbsETyHUeBLQ8jLtxlh...   \n",
       "4  /data/train/20200413/FGRDO4IBbAejR0WHD5YbkXTCa...   \n",
       "\n",
       "                                             vowel-e  \\\n",
       "0  /data/train/20200413/vK2bLRNzllXNeyOMudnNSL5cf...   \n",
       "1  /data/train/20200413/bjA2KpSxneNskrLBeqi4bqoTD...   \n",
       "2  /data/train/20200413/FSzobvJqOXf0rI6X05cHqOiU9...   \n",
       "3  /data/train/20200413/EqDWckxbsETyHUeBLQ8jLtxlh...   \n",
       "4  /data/train/20200413/FGRDO4IBbAejR0WHD5YbkXTCa...   \n",
       "\n",
       "                                             vowel-o  split  \n",
       "0  /data/train/20200413/vK2bLRNzllXNeyOMudnNSL5cf...      0  \n",
       "1  /data/train/20200413/bjA2KpSxneNskrLBeqi4bqoTD...      0  \n",
       "2  /data/train/20200413/FSzobvJqOXf0rI6X05cHqOiU9...      0  \n",
       "3  /data/train/20200413/EqDWckxbsETyHUeBLQ8jLtxlh...      0  \n",
       "4  /data/train/20200413/FGRDO4IBbAejR0WHD5YbkXTCa...      0  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_meta2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "def preprocess_other(sample):\n",
    "  image_target_height, image_target_width = 64, 64 #setting up the shape of sample\n",
    "  audio_binary = tf.io.read_file(sample) #read-in the sample \n",
    "  audio, rate = tf.audio.decode_wav(audio_binary, desired_channels=1) #getting the audio and rate\n",
    "  #label = sample['label']\n",
    "\n",
    "  def py_preprocess_audio(audio):\n",
    "      audio = audio.numpy().astype('float32')\n",
    "\n",
    "      spectogram = librosa.feature.melspectrogram(\n",
    "        y=audio, n_fft=1024,  n_mels=64, hop_length=64, sr=8000, fmax=2000 #n_fft = window size, n_mels = frequency bins, hop_lenghth =jump to the right , sr = sound rate, fmax = \n",
    "      ) \n",
    "\n",
    "      spectogram /= np.max(spectogram) #devide by np.max(audio)\n",
    "      spectogram = cv2.resize(spectogram, dsize=(image_target_height, image_target_width))\n",
    "      spectogram = np.expand_dims(spectogram, axis=-1)\n",
    "      return spectogram\n",
    "\n",
    "  spectogram = tf.py_function(py_preprocess_audio, [audio], tf.float32)\n",
    "  spectogram.set_shape((image_target_height, image_target_width, 1))\n",
    "\n",
    "  return spectogram#, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " ...\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]], shape=(864256, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#test\n",
    "path = './CoronaHack-Respiratory-Sound-Dataset' + df_meta.loc[16,'counting-normal']\n",
    "#print(path)\n",
    "def pr(sample):\n",
    "    image_target_height, image_target_width = 64, 64 #setting up the shape of sample\n",
    "    audio_binary = tf.io.read_file(sample) #read-in the sample \n",
    "    audio, rate = tf.audio.decode_wav(audio_binary, desired_channels=1) #getting the audio and rate\n",
    "    #audio = audio[:,0]\n",
    "    #print(audio.shape)\n",
    "    return(audio)\n",
    "\n",
    "print(pr(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: (None, 64, 64, 1), types: tf.float32>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_counnting_normal = df_meta2['counting-normal'].tolist()\n",
    "path_counnting_normal = ['./CoronaHack-Respiratory-Sound-Dataset' + dir_name for dir_name in path_counnting_normal]\n",
    "#labels = tf.convert_to_tensor()\n",
    "\n",
    "\n",
    "\n",
    "# Convert to Tensor\n",
    "sound_paths_counnting_normal = tf.convert_to_tensor(path_counnting_normal, dtype=tf.string)\n",
    "# Build a TF Queue, shuffle data\n",
    "#sound,labels = tf.data.Dataset.from_tensor_slices([sound_paths_counnting_normal, labels])\n",
    "#make tensor slices and map in batches of 32\n",
    "sound = tf.data.Dataset.from_tensor_slices(sound_paths_counnting_normal)\n",
    "x = sound.map(lambda sample: preprocess_other(sample)).batch(32)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['counting-normal','counting-fast','breathing-deep','breathing-shallow','cough-heavy','cough-shallow','vowel-a','vowel-e','vowel-o']\n",
    "input_dic = {}\n",
    "for index,name in enumerate(names):\n",
    "    #print(index,name)\n",
    "    path_list = df_meta2[name].tolist()\n",
    "    #print(path_list[:10])\n",
    "    path_name = ['./CoronaHack-Respiratory-Sound-Dataset'  + str(dir_name for dir_name in path_list)]\n",
    "    sound_paths_tensor = tf.convert_to_tensor(path_name, dtype=tf.string)\n",
    "    sound = tf.data.Dataset.from_tensor_slices(sound_paths_tensor)\n",
    "    input_dic['x_{}'.format(index)] = sound.map(lambda sample: preprocess_other(sample))\n",
    "\n",
    "\n",
    "name_label = 'split'\n",
    "path_label = df_meta2[name_label].tolist()\n",
    "label_paths_tensor = tf.convert_to_tensor(path_label, dtype=tf.int16)\n",
    "y = tf.data.Dataset.from_tensor_slices(label_paths_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_input = ['counting-normal','counting-fast','breathing-deep','breathing-shallow','cough-heavy','cough-shallow','vowel-a','vowel-e','vowel-o']\n",
    "name_label = 'split'\n",
    "\n",
    "def create_input_label(df=df_meta2,names=names_input,name_label=name_label):\n",
    "    input_dic = {}\n",
    "    for index,name in enumerate(names):\n",
    "        #print(index,name)\n",
    "        path_list = df[name].tolist()\n",
    "        #print(path_list[:10])\n",
    "        path_name = ['./CoronaHack-Respiratory-Sound-Dataset'  + str(dir_name for dir_name in path_list)]\n",
    "        sound_paths_tensor = tf.convert_to_tensor(path_name, dtype=tf.string)\n",
    "        input_dic['x_{}'.format(index)] = sound.map(lambda sample: preprocess_other(sample))\n",
    "\n",
    "\n",
    "    path_label = df_meta2[name_label].tolist()\n",
    "    y = tf.convert_to_tensor(path_label, dtype=tf.int16)\n",
    "\n",
    "    return input_dic,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _input_fn():\n",
    "  input_dict,labels = create_input_label(df=df_meta2,names=names_input,name_label=name_label)\n",
    "  dataset = tf.data.Dataset.from_tensor_slices((input_dict, labels))\n",
    "  dataset = dataset.batch(32, drop_remainder=True)\n",
    "  return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_8 (Conv2D)            (None, 64, 64, 4)         40        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 32, 32, 4)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 32, 32, 8)         296       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 16, 16, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 16, 16, 8)         584       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 8, 8, 8)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 8, 8, 16)          1168      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 4, 4, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 18,666\n",
      "Trainable params: 18,666\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import models, layers\n",
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Conv2D(4, (3,3), activation='relu', padding='same', input_shape=(64,64,1))) #3,3 is the pixel window for screen and is a common standard, 4 is also a parameter\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "model.add(layers.Conv2D(8, (3,3),activation='relu', padding='same'))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "model.add(layers.Conv2D(8, (3,3),activation='relu', padding='same'))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "model.add(layers.Conv2D(16, (3,3),activation='relu', padding='same'))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "\n",
    "model.add(layers.Dense(2, activation='sigmoid'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    #metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unbatching a dataset is only supported for rank >= 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-60-5c43b9b35bd1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m history = model.fit(\n\u001b[1;32m----> 4\u001b[1;33m      \u001b[0m_input_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;31m#batch_size=32\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-58-171eeacdb9ff>\u001b[0m in \u001b[0;36m_input_fn\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_input_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m   \u001b[0minput_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_input_label\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf_meta2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnames\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnames_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mname_label\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname_label\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m   \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_tensor_slices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m   \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdrop_remainder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\corona\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36mfrom_tensor_slices\u001b[1;34m(tensors)\u001b[0m\n\u001b[0;32m    683\u001b[0m       \u001b[0mDataset\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    684\u001b[0m     \"\"\"\n\u001b[1;32m--> 685\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mTensorSliceDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    686\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    687\u001b[0m   \u001b[1;32mclass\u001b[0m \u001b[0m_GeneratorState\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\corona\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, element)\u001b[0m\n\u001b[0;32m   3844\u001b[0m     \u001b[0melement\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormalize_element\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melement\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3845\u001b[0m     \u001b[0mbatched_spec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype_spec_from_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melement\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3846\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tensors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_batched_tensor_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatched_spec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0melement\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3847\u001b[0m     self._structure = nest.map_structure(\n\u001b[0;32m   3848\u001b[0m         lambda component_spec: component_spec._unbatch(), batched_spec)  # pylint: disable=protected-access\n",
      "\u001b[1;32m~\\.conda\\envs\\corona\\lib\\site-packages\\tensorflow\\python\\data\\util\\structure.py\u001b[0m in \u001b[0;36mto_batched_tensor_list\u001b[1;34m(element_spec, element)\u001b[0m\n\u001b[0;32m    364\u001b[0m   return _to_tensor_list_helper(\n\u001b[0;32m    365\u001b[0m       lambda state, spec, component: state + spec._to_batched_tensor_list(\n\u001b[1;32m--> 366\u001b[1;33m           component), element_spec, element)\n\u001b[0m\u001b[0;32m    367\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    368\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\corona\\lib\\site-packages\\tensorflow\\python\\data\\util\\structure.py\u001b[0m in \u001b[0;36m_to_tensor_list_helper\u001b[1;34m(encode_fn, element_spec, element)\u001b[0m\n\u001b[0;32m    338\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    339\u001b[0m   return functools.reduce(\n\u001b[1;32m--> 340\u001b[1;33m       reduce_fn, zip(nest.flatten(element_spec), nest.flatten(element)), [])\n\u001b[0m\u001b[0;32m    341\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    342\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\corona\\lib\\site-packages\\tensorflow\\python\\data\\util\\structure.py\u001b[0m in \u001b[0;36mreduce_fn\u001b[1;34m(state, value)\u001b[0m\n\u001b[0;32m    335\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mreduce_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    336\u001b[0m     \u001b[0mspec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcomponent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 337\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mencode_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mspec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcomponent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    338\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    339\u001b[0m   return functools.reduce(\n",
      "\u001b[1;32m~\\.conda\\envs\\corona\\lib\\site-packages\\tensorflow\\python\\data\\util\\structure.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(state, spec, component)\u001b[0m\n\u001b[0;32m    364\u001b[0m   return _to_tensor_list_helper(\n\u001b[0;32m    365\u001b[0m       lambda state, spec, component: state + spec._to_batched_tensor_list(\n\u001b[1;32m--> 366\u001b[1;33m           component), element_spec, element)\n\u001b[0m\u001b[0;32m    367\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    368\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\corona\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36m_to_batched_tensor_list\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m   4016\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_to_batched_tensor_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4017\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_shape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndims\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4018\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Unbatching a dataset is only supported for rank >= 1\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4019\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_to_tensor_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4020\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Unbatching a dataset is only supported for rank >= 1"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "history_list = {}\n",
    "\n",
    "history = model.fit(\n",
    "     _input_fn(),\n",
    "    epochs = 20,\n",
    "    #batch_size=32\n",
    "\n",
    ")\n",
    "\n",
    "history_list['base'] = history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            [(None, 64, 64, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_8 (InputLayer)            [(None, 64, 64, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 128, 64, 1)   0           input_7[0][0]                    \n",
      "                                                                 input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 128, 64, 4)   40          concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling2D) (None, 64, 32, 4)    0           conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)             (None, 8192)         0           max_pooling2d_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 64)           524352      flatten_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 2)            130         dense_10[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 524,522\n",
      "Trainable params: 524,522\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input1 = keras.layers.Input(shape=(64,64,1, ))\n",
    "input2 = keras.layers.Input(shape=(64,64,1,))\n",
    "merged = keras.layers.Concatenate(axis=1)([input1, input2])\n",
    "\n",
    "cv2_first = layers.Conv2D(4, (3,3), activation='relu', padding='same',  input_dim=2,)(merged) #3,3 is the pixel window for screen and is a common standard, 4 is also a parameter\n",
    "pooling_1 = layers.MaxPooling2D((2,2))(cv2_first)\n",
    "\n",
    "\n",
    "flatten = layers.Flatten()(pooling_1)\n",
    "\n",
    "densse_1 = layers.Dense(64, activation='relu')(flatten)\n",
    "\n",
    "output = layers.Dense(2, activation='sigmoid')(densse_1)\n",
    "\n",
    "model_api = keras.models.Model(inputs=[input1, input2], outputs=output)\n",
    "\n",
    "model_api.summary()\n",
    "\n",
    "model_api.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    #metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to find data adapter that can handle input: (<class 'list'> containing values of types {\"<class 'tensorflow.python.data.ops.dataset_ops.MapDataset'>\"}), <class 'tensorflow.python.framework.ops.EagerTensor'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-68-92fed32212e2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0minput_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_input_label\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf_meta2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnames\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnames_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mname_label\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname_label\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mmodel_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0minput_dic\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'x_0'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_dic\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'x_1'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\.conda\\envs\\corona\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1146\u001b[0m           \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1147\u001b[0m           \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1148\u001b[1;33m           steps_per_execution=self._steps_per_execution)\n\u001b[0m\u001b[0;32m   1149\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1150\u001b[0m       \u001b[1;31m# Container that configures and calls `tf.keras.Callback`s.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\corona\\lib\\site-packages\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36mget_data_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1381\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"model\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"_cluster_coordinator\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1382\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_ClusterCoordinatorDataHandler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1383\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mDataHandler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1384\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1385\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\corona\\lib\\site-packages\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute)\u001b[0m\n\u001b[0;32m   1135\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_steps_per_execution_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msteps_per_execution\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1136\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1137\u001b[1;33m     \u001b[0madapter_cls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mselect_data_adapter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1138\u001b[0m     self._adapter = adapter_cls(\n\u001b[0;32m   1139\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\corona\\lib\\site-packages\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36mselect_data_adapter\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m    977\u001b[0m         \u001b[1;34m\"Failed to find data adapter that can handle \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    978\u001b[0m         \"input: {}, {}\".format(\n\u001b[1;32m--> 979\u001b[1;33m             _type_name(x), _type_name(y)))\n\u001b[0m\u001b[0;32m    980\u001b[0m   \u001b[1;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0madapter_cls\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    981\u001b[0m     raise RuntimeError(\n",
      "\u001b[1;31mValueError\u001b[0m: Failed to find data adapter that can handle input: (<class 'list'> containing values of types {\"<class 'tensorflow.python.data.ops.dataset_ops.MapDataset'>\"}), <class 'tensorflow.python.framework.ops.EagerTensor'>"
     ]
    }
   ],
   "source": [
    "input_dict,labels = create_input_label(df=df_meta2,names=names_input,name_label=name_label)\n",
    "\n",
    "model_api.fit([input_dic['x_0'], input_dic['x_1']],labels, batch_size=16, epochs=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1396,), dtype=int16, numpy=array([0, 0, 0, ..., 1, 0, 0], dtype=int16)>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wav_to_mel(file_path):\n",
    "    image_target_height, image_target_width = 64, 64\n",
    "    audio_binary = tf.io.read_file(file_path)\n",
    "    audio, rate = tf.audio.decode_wav(audio_binary, desired_channels=1)\n",
    "    #waveform = tf.squeeze(audio, axis=-1)\n",
    "    audio = audio[:,0]\n",
    "    print(audio.shape)\n",
    "    position = tfio.audio.trim(audio, axis=0, epsilon=0.1)\n",
    "    print(position[0])\n",
    "    start = position[0]\n",
    "    end = position[1]\n",
    "    audio= audio[start:end]\n",
    "\n",
    "    # Normalize audio data\n",
    "    audio = tf.cast(audio, tf.float32) / 32768.0  # Max int for audio data\n",
    "    # Create the spectogram from audio data\n",
    "    spectrogram = tfio.audio.spectrogram(\n",
    "        audio, nfft=1024, window=128, stride=64\n",
    "    )\n",
    "    # Turn spectrogram into mel spectrogram\n",
    "    spectrogram = tfio.audio.melscale(\n",
    "        spectrogram, rate=rate, mels=64, fmin=0, fmax=2000\n",
    "    )\n",
    "\n",
    "    #spectrogram /= np.max(audio)\n",
    "    spectrogram /= tf.math.reduce_max(spectrogram) # Normalize\n",
    "    spectrogram = tf.expand_dims(spectrogram, axis=-1) # 2D -> 3D\n",
    "    spectrogram = tf.image.resize(spectrogram, (image_target_height, image_target_width)) # Resize the picture\n",
    "    spectrogram = tf.transpose(spectrogram, perm=(1, 0, 2)) # Swap the first two axis\n",
    "    spectrogram = spectrogram[::-1, :, :] # Flip the first axis (frequency)\n",
    "\n",
    "    #display(Audio(audio, rate=8000))\n",
    "   \n",
    "    return spectrogram\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnknownError",
     "evalue": "ParameterError: Invalid shape for monophonic audio: ndim=2, shape=(196608, 1)\nTraceback (most recent call last):\n\n  File \"C:\\Users\\paulg\\.conda\\envs\\corona\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 247, in __call__\n    return func(device, token, args)\n\n  File \"C:\\Users\\paulg\\.conda\\envs\\corona\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 135, in __call__\n    ret = self._func(*args)\n\n  File \"C:\\Users\\paulg\\.conda\\envs\\corona\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 645, in wrapper\n    return func(*args, **kwargs)\n\n  File \"<ipython-input-10-867061280308>\", line 12, in py_preprocess_audio\n    y=audio, n_fft=1024,  n_mels=64, hop_length=64, sr=8000, fmax=2000 #n_fft = window size, n_mels = frequency bins, hop_lenghth =jump to the right , sr = sound rate, fmax =\n\n  File \"C:\\Users\\paulg\\.conda\\envs\\corona\\lib\\site-packages\\librosa\\feature\\spectral.py\", line 2004, in melspectrogram\n    pad_mode=pad_mode,\n\n  File \"C:\\Users\\paulg\\.conda\\envs\\corona\\lib\\site-packages\\librosa\\core\\spectrum.py\", line 2519, in _spectrogram\n    pad_mode=pad_mode,\n\n  File \"C:\\Users\\paulg\\.conda\\envs\\corona\\lib\\site-packages\\librosa\\core\\spectrum.py\", line 217, in stft\n    util.valid_audio(y)\n\n  File \"C:\\Users\\paulg\\.conda\\envs\\corona\\lib\\site-packages\\librosa\\util\\utils.py\", line 295, in valid_audio\n    \"ndim={:d}, shape={}\".format(y.ndim, y.shape)\n\nlibrosa.util.exceptions.ParameterError: Invalid shape for monophonic audio: ndim=2, shape=(196608, 1)\n\n [Op:EagerPyFunc]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-9ea5f79d9d9f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_meta2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'./CoronaHack-Respiratory-Sound-Dataset'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdf_meta2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msound\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[0mspects\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreprocess_other\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;31m#spects\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-867061280308>\u001b[0m in \u001b[0;36mpreprocess_other\u001b[1;34m(sample)\u001b[0m\n\u001b[0;32m     18\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mspectogram\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m   \u001b[0mspectogram\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpy_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpy_preprocess_audio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0maudio\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m   \u001b[0mspectogram\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_target_height\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage_target_width\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\corona\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    204\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\corona\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\u001b[0m in \u001b[0;36meager_py_func\u001b[1;34m(func, inp, Tout, name)\u001b[0m\n\u001b[0;32m    511\u001b[0m   \"\"\"\n\u001b[0;32m    512\u001b[0m   return _eager_py_func(\n\u001b[1;32m--> 513\u001b[1;33m       func=func, inp=inp, Tout=Tout, name=name, use_tape_cache=True)\n\u001b[0m\u001b[0;32m    514\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    515\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\corona\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\u001b[0m in \u001b[0;36m_eager_py_func\u001b[1;34m(func, inp, Tout, name, use_tape_cache)\u001b[0m\n\u001b[0;32m    418\u001b[0m           \u001b[0meager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    419\u001b[0m           \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 420\u001b[1;33m           use_tape_cache=use_tape_cache)\n\u001b[0m\u001b[0;32m    421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    422\u001b[0m   return _internal_py_func(\n",
      "\u001b[1;32m~\\.conda\\envs\\corona\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\u001b[0m in \u001b[0;36m_internal_py_func\u001b[1;34m(func, inp, Tout, stateful, eager, is_grad_func, name, use_tape_cache)\u001b[0m\n\u001b[0;32m    346\u001b[0m         \u001b[0mis_async\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m         \u001b[0mTout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTout\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 348\u001b[1;33m         name=name)\n\u001b[0m\u001b[0;32m    349\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    350\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mstateful\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\corona\\lib\\site-packages\\tensorflow\\python\\ops\\gen_script_ops.py\u001b[0m in \u001b[0;36meager_py_func\u001b[1;34m(input, token, Tout, is_async, name)\u001b[0m\n\u001b[0;32m     46\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m       \u001b[0m_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m       \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\corona\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   6939\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\" name: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6940\u001b[0m   \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6941\u001b[1;33m   \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6942\u001b[0m   \u001b[1;31m# pylint: enable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6943\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\corona\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mUnknownError\u001b[0m: ParameterError: Invalid shape for monophonic audio: ndim=2, shape=(196608, 1)\nTraceback (most recent call last):\n\n  File \"C:\\Users\\paulg\\.conda\\envs\\corona\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 247, in __call__\n    return func(device, token, args)\n\n  File \"C:\\Users\\paulg\\.conda\\envs\\corona\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 135, in __call__\n    ret = self._func(*args)\n\n  File \"C:\\Users\\paulg\\.conda\\envs\\corona\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 645, in wrapper\n    return func(*args, **kwargs)\n\n  File \"<ipython-input-10-867061280308>\", line 12, in py_preprocess_audio\n    y=audio, n_fft=1024,  n_mels=64, hop_length=64, sr=8000, fmax=2000 #n_fft = window size, n_mels = frequency bins, hop_lenghth =jump to the right , sr = sound rate, fmax =\n\n  File \"C:\\Users\\paulg\\.conda\\envs\\corona\\lib\\site-packages\\librosa\\feature\\spectral.py\", line 2004, in melspectrogram\n    pad_mode=pad_mode,\n\n  File \"C:\\Users\\paulg\\.conda\\envs\\corona\\lib\\site-packages\\librosa\\core\\spectrum.py\", line 2519, in _spectrogram\n    pad_mode=pad_mode,\n\n  File \"C:\\Users\\paulg\\.conda\\envs\\corona\\lib\\site-packages\\librosa\\core\\spectrum.py\", line 217, in stft\n    util.valid_audio(y)\n\n  File \"C:\\Users\\paulg\\.conda\\envs\\corona\\lib\\site-packages\\librosa\\util\\utils.py\", line 295, in valid_audio\n    \"ndim={:d}, shape={}\".format(y.ndim, y.shape)\n\nlibrosa.util.exceptions.ParameterError: Invalid shape for monophonic audio: ndim=2, shape=(196608, 1)\n\n [Op:EagerPyFunc]"
     ]
    }
   ],
   "source": [
    "import tensorflow_io as tfio\n",
    "from IPython.display import Audio, display\n",
    "\n",
    "sounds = ['counting-fast','counting-normal']\n",
    "spects = {}\n",
    "# initialize with empty list\n",
    "for i in range(len(df_meta2)):\n",
    "        spects[i] = []\n",
    "# create spect for each sound\n",
    "for sound in sounds:\n",
    "    for i in range(len(df_meta2)):\n",
    "        path = './CoronaHack-Respiratory-Sound-Dataset' + df_meta2.loc[i,sound]\n",
    "        spects[i].append(preprocess_other(path))\n",
    "\n",
    "#spects   \n",
    "print(spects)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydub in c:\\users\\paulg\\.conda\\envs\\corona\\lib\\site-packages (0.25.1)\n",
      "Collecting tensorflow_io\n",
      "  Downloading tensorflow_io-0.21.0-cp36-cp36m-win_amd64.whl (21.3 MB)\n",
      "Requirement already satisfied: tensorflow<2.7.0,>=2.6.0 in c:\\users\\paulg\\.conda\\envs\\corona\\lib\\site-packages (from tensorflow_io) (2.6.0)\n",
      "Collecting tensorflow-io-gcs-filesystem==0.21.0\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.21.0-cp36-cp36m-win_amd64.whl (1.5 MB)\n",
      "Requirement already satisfied: tensorboard~=2.6 in c:\\users\\paulg\\.conda\\envs\\corona\\lib\\site-packages (from tensorflow<2.7.0,>=2.6.0->tensorflow_io) (2.6.0)\n",
      "Requirement already satisfied: absl-py~=0.10 in c:\\users\\paulg\\.conda\\envs\\corona\\lib\\site-packages (from tensorflow<2.7.0,>=2.6.0->tensorflow_io) (0.13.0)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in c:\\users\\paulg\\.conda\\envs\\corona\\lib\\site-packages (from tensorflow<2.7.0,>=2.6.0->tensorflow_io) (1.6.3)\n",
      "Requirement already satisfied: numpy~=1.19.2 in c:\\users\\paulg\\.conda\\envs\\corona\\lib\\site-packages (from tensorflow<2.7.0,>=2.6.0->tensorflow_io) (1.19.5)\n",
      "Requirement already satisfied: google-pasta~=0.2 in c:\\users\\paulg\\.conda\\envs\\corona\\lib\\site-packages (from tensorflow<2.7.0,>=2.6.0->tensorflow_io) (0.2.0)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in c:\\users\\paulg\\.conda\\envs\\corona\\lib\\site-packages (from tensorflow<2.7.0,>=2.6.0->tensorflow_io) (3.3.0)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in c:\\users\\paulg\\.conda\\envs\\corona\\lib\\site-packages (from tensorflow<2.7.0,>=2.6.0->tensorflow_io) (1.1.0)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in c:\\users\\paulg\\.conda\\envs\\corona\\lib\\site-packages (from tensorflow<2.7.0,>=2.6.0->tensorflow_io) (1.12.1)\n",
      "Requirement already satisfied: tensorflow-estimator~=2.6 in c:\\users\\paulg\\.conda\\envs\\corona\\lib\\site-packages (from tensorflow<2.7.0,>=2.6.0->tensorflow_io) (2.6.0)\n",
      "Requirement already satisfied: gast==0.4.0 in c:\\users\\paulg\\.conda\\envs\\corona\\lib\\site-packages (from tensorflow<2.7.0,>=2.6.0->tensorflow_io) (0.4.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in c:\\users\\paulg\\.conda\\envs\\corona\\lib\\site-packages (from tensorflow<2.7.0,>=2.6.0->tensorflow_io) (3.18.0)\n",
      "Requirement already satisfied: six~=1.15.0 in c:\\users\\paulg\\.conda\\envs\\corona\\lib\\site-packages (from tensorflow<2.7.0,>=2.6.0->tensorflow_io) (1.15.0)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in c:\\users\\paulg\\.conda\\envs\\corona\\lib\\site-packages (from tensorflow<2.7.0,>=2.6.0->tensorflow_io) (3.7.4.3)\n",
      "Requirement already satisfied: wheel~=0.35 in c:\\users\\paulg\\.conda\\envs\\corona\\lib\\site-packages (from tensorflow<2.7.0,>=2.6.0->tensorflow_io) (0.37.0)\n",
      "Requirement already satisfied: keras~=2.6 in c:\\users\\paulg\\.conda\\envs\\corona\\lib\\site-packages (from tensorflow<2.7.0,>=2.6.0->tensorflow_io) (2.6.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.37.0 in c:\\users\\paulg\\.conda\\envs\\corona\\lib\\site-packages (from tensorflow<2.7.0,>=2.6.0->tensorflow_io) (1.40.0)\n",
      "Requirement already satisfied: h5py~=3.1.0 in c:\\users\\paulg\\.conda\\envs\\corona\\lib\\site-packages (from tensorflow<2.7.0,>=2.6.0->tensorflow_io) (3.1.0)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in c:\\users\\paulg\\.conda\\envs\\corona\\lib\\site-packages (from tensorflow<2.7.0,>=2.6.0->tensorflow_io) (1.1.2)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in c:\\users\\paulg\\.conda\\envs\\corona\\lib\\site-packages (from tensorflow<2.7.0,>=2.6.0->tensorflow_io) (1.12)\n",
      "Requirement already satisfied: clang~=5.0 in c:\\users\\paulg\\.conda\\envs\\corona\\lib\\site-packages (from tensorflow<2.7.0,>=2.6.0->tensorflow_io) (5.0)\n",
      "Requirement already satisfied: cached-property in c:\\users\\paulg\\.conda\\envs\\corona\\lib\\site-packages (from h5py~=3.1.0->tensorflow<2.7.0,>=2.6.0->tensorflow_io) (1.5.2)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in c:\\users\\paulg\\.conda\\envs\\corona\\lib\\site-packages (from tensorboard~=2.6->tensorflow<2.7.0,>=2.6.0->tensorflow_io) (1.35.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\paulg\\.conda\\envs\\corona\\lib\\site-packages (from tensorboard~=2.6->tensorflow<2.7.0,>=2.6.0->tensorflow_io) (0.4.6)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\paulg\\.conda\\envs\\corona\\lib\\site-packages (from tensorboard~=2.6->tensorflow<2.7.0,>=2.6.0->tensorflow_io) (1.8.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\paulg\\.conda\\envs\\corona\\lib\\site-packages (from tensorboard~=2.6->tensorflow<2.7.0,>=2.6.0->tensorflow_io) (52.0.0.post20210125)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\paulg\\.conda\\envs\\corona\\lib\\site-packages (from tensorboard~=2.6->tensorflow<2.7.0,>=2.6.0->tensorflow_io) (2.0.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\paulg\\.conda\\envs\\corona\\lib\\site-packages (from tensorboard~=2.6->tensorflow<2.7.0,>=2.6.0->tensorflow_io) (0.6.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\paulg\\.conda\\envs\\corona\\lib\\site-packages (from tensorboard~=2.6->tensorflow<2.7.0,>=2.6.0->tensorflow_io) (3.3.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\paulg\\.conda\\envs\\corona\\lib\\site-packages (from tensorboard~=2.6->tensorflow<2.7.0,>=2.6.0->tensorflow_io) (2.26.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\paulg\\.conda\\envs\\corona\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow<2.7.0,>=2.6.0->tensorflow_io) (4.7.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\paulg\\.conda\\envs\\corona\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow<2.7.0,>=2.6.0->tensorflow_io) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\paulg\\.conda\\envs\\corona\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow<2.7.0,>=2.6.0->tensorflow_io) (4.2.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\paulg\\.conda\\envs\\corona\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow<2.7.0,>=2.6.0->tensorflow_io) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata in c:\\users\\paulg\\.conda\\envs\\corona\\lib\\site-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow<2.7.0,>=2.6.0->tensorflow_io) (4.6.4)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\paulg\\.conda\\envs\\corona\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow<2.7.0,>=2.6.0->tensorflow_io) (0.4.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\paulg\\.conda\\envs\\corona\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow<2.7.0,>=2.6.0->tensorflow_io) (2021.5.30)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\paulg\\.conda\\envs\\corona\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow<2.7.0,>=2.6.0->tensorflow_io) (3.2)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\paulg\\.conda\\envs\\corona\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow<2.7.0,>=2.6.0->tensorflow_io) (2.0.5)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\paulg\\.conda\\envs\\corona\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow<2.7.0,>=2.6.0->tensorflow_io) (1.26.6)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\paulg\\.conda\\envs\\corona\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow<2.7.0,>=2.6.0->tensorflow_io) (3.1.1)\n",
      "Requirement already satisfied: dataclasses in c:\\users\\paulg\\.conda\\envs\\corona\\lib\\site-packages (from werkzeug>=0.11.15->tensorboard~=2.6->tensorflow<2.7.0,>=2.6.0->tensorflow_io) (0.8)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\paulg\\.conda\\envs\\corona\\lib\\site-packages (from importlib-metadata->markdown>=2.6.8->tensorboard~=2.6->tensorflow<2.7.0,>=2.6.0->tensorflow_io) (3.5.0)\n",
      "Installing collected packages: tensorflow-io-gcs-filesystem, tensorflow-io\n",
      "Successfully installed tensorflow-io-0.21.0 tensorflow-io-gcs-filesystem-0.21.0\n"
     ]
    }
   ],
   "source": [
    " !pip install pydub tensorflow_io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "\n",
    "def load_data(data_directory):\n",
    "    directories = [d for d in os.listdir(data_directory) \n",
    "                   if os.path.isdir(os.path.join(data_directory, d))]\n",
    "    labels = []\n",
    "    sound = []\n",
    "    for d in directories:\n",
    "        label_directory = os.path.join(data_directory, d)\n",
    "        file_names = [os.path.join(label_directory, f) \n",
    "                      for f in os.listdir(label_directory) \n",
    "                      if f.endswith(\".wav\")]\n",
    "        for f in file_names:\n",
    "            images.append(skimage.data.imread(f))\n",
    "            labels.append(int(d))\n",
    "    return images, labels\n",
    "\n",
    "ROOT_PATH = \"/your/root/path\"\n",
    "train_data_directory = os.path.join(ROOT_PATH, \"./CoronaHack-Respiratory-Sound-Dataset/data/train\")\n",
    "test_data_directory = os.path.join(ROOT_PATH, \"./CoronaHack-Respiratory-Sound-Dataset/data/test\")\n",
    "\n",
    "images, labels = load_data(train_data_directory)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8e06dae36da5af555d220c5b5d98ac2c0ea1251ccd3307154d7e0f059350ea4f"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
