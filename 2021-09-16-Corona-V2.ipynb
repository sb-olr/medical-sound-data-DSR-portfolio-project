{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Corona Setup"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "#Data visualization\r\n",
    "\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "import seaborn as sns\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "\r\n",
    "#Audio Analysis\r\n",
    "import glob\r\n",
    "import IPython\r\n",
    "import librosa\r\n",
    "import librosa.display\r\n",
    "import tensorflow as tf\r\n",
    "from tensorflow import keras\r\n",
    "\r\n",
    "#path\r\n",
    "import os\r\n",
    "\r\n",
    "#"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "#import meta data\r\n",
    "\r\n",
    "df_meta = pd.read_csv('./CoronaHack-Respiratory-Sound-Dataset/Corona-Hack-Respiratory-Sound-Metadata.csv')\r\n",
    "df_meta.info(), df_meta.shape\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1397 entries, 0 to 1396\n",
      "Data columns (total 37 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   USER_ID                 1397 non-null   object \n",
      " 1   COUNTRY                 1397 non-null   object \n",
      " 2   AGE                     1397 non-null   int64  \n",
      " 3   COVID_STATUS            1396 non-null   object \n",
      " 4   ENGLISH_PROFICIENCY     1397 non-null   object \n",
      " 5   GENDER                  1397 non-null   object \n",
      " 6   COUNTY_RO_STATE         1397 non-null   object \n",
      " 7   CITY_LOCALITY           1228 non-null   object \n",
      " 8   Diabetes                1397 non-null   int64  \n",
      " 9   Asthma                  1397 non-null   int64  \n",
      " 10  Smoker                  1397 non-null   int64  \n",
      " 11  Hypertension            1397 non-null   int64  \n",
      " 12  Fever                   1397 non-null   int64  \n",
      " 13  Returning_User          1397 non-null   int64  \n",
      " 14  Using_Mask              1397 non-null   int64  \n",
      " 15  Cold                    1397 non-null   int64  \n",
      " 16  Caugh                   1397 non-null   int64  \n",
      " 17  Muscle_Pain             1397 non-null   int64  \n",
      " 18  loss_of_smell           1397 non-null   int64  \n",
      " 19  Sore_Throat             1397 non-null   int64  \n",
      " 20  Fatigue                 1397 non-null   int64  \n",
      " 21  Breathing_Difficulties  1397 non-null   int64  \n",
      " 22  Chronic_Lung_Disease    1397 non-null   int64  \n",
      " 23  Ischemic_Heart_Disease  1397 non-null   int64  \n",
      " 24  Pneumonia               1397 non-null   int64  \n",
      " 25  COVID_test_status       1355 non-null   float64\n",
      " 26  Diarrheoa               1397 non-null   int64  \n",
      " 27  DATES                   1397 non-null   int64  \n",
      " 28  breathing-deep          1396 non-null   object \n",
      " 29  breathing-shallow       1396 non-null   object \n",
      " 30  cough-heavy             1396 non-null   object \n",
      " 31  cough-shallow           1395 non-null   object \n",
      " 32  counting-fast           1397 non-null   object \n",
      " 33  counting-normal         1397 non-null   object \n",
      " 34  vowel-a                 1396 non-null   object \n",
      " 35  vowel-e                 1396 non-null   object \n",
      " 36  vowel-o                 1395 non-null   object \n",
      "dtypes: float64(1), int64(20), object(16)\n",
      "memory usage: 403.9+ KB\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(None, (1397, 37))"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "#Use path info from csv file to load data \r\n",
    "\r\n",
    "#split COVID STATUS to get labels\r\n",
    "df_meta['split'] = df_meta['COVID_STATUS'].str.split('_').str.get(0)\r\n",
    "#Check for NA\r\n",
    "df_meta.loc[:,'counting-normal'].isna().sum()\r\n",
    "df_meta.loc[:,'split'].value_counts()\r\n",
    "\r\n",
    "#Generate a dict to categorize split column\r\n",
    "cat_dict = {'healthy':0,'no':0,'resp':0,'recovered':0,'positive':1}\r\n",
    "\r\n",
    "#map cat_dict to split column \r\n",
    "df_meta.loc[:,'split'] =  df_meta.loc[:,'split'].map(cat_dict)\r\n",
    "df_meta2 = df_meta.dropna(subset=['split'])\r\n",
    "\r\n",
    "\r\n",
    "#Extract positive USER ID\r\n",
    "df_meta_positives = df_meta[df_meta['split'] == 1]\r\n",
    "df_meta_negatives = df_meta[df_meta['split'] == 0]\r\n",
    "\r\n",
    "positives = list(df_meta_positives['USER_ID'])\r\n",
    "negatives = list(df_meta_negatives['USER_ID'])\r\n",
    "len(positives),len(negatives)\r\n",
    "#positives"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(56, 1340)"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "df_meta2.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>USER_ID</th>\n",
       "      <th>COUNTRY</th>\n",
       "      <th>AGE</th>\n",
       "      <th>COVID_STATUS</th>\n",
       "      <th>ENGLISH_PROFICIENCY</th>\n",
       "      <th>GENDER</th>\n",
       "      <th>COUNTY_RO_STATE</th>\n",
       "      <th>CITY_LOCALITY</th>\n",
       "      <th>Diabetes</th>\n",
       "      <th>Asthma</th>\n",
       "      <th>...</th>\n",
       "      <th>breathing-deep</th>\n",
       "      <th>breathing-shallow</th>\n",
       "      <th>cough-heavy</th>\n",
       "      <th>cough-shallow</th>\n",
       "      <th>counting-fast</th>\n",
       "      <th>counting-normal</th>\n",
       "      <th>vowel-a</th>\n",
       "      <th>vowel-e</th>\n",
       "      <th>vowel-o</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vK2bLRNzllXNeyOMudnNSL5cfpG2</td>\n",
       "      <td>India</td>\n",
       "      <td>24</td>\n",
       "      <td>healthy</td>\n",
       "      <td>Y</td>\n",
       "      <td>M</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>/data/train/20200413/vK2bLRNzllXNeyOMudnNSL5cf...</td>\n",
       "      <td>/data/train/20200413/vK2bLRNzllXNeyOMudnNSL5cf...</td>\n",
       "      <td>/data/train/20200413/vK2bLRNzllXNeyOMudnNSL5cf...</td>\n",
       "      <td>/data/train/20200413/vK2bLRNzllXNeyOMudnNSL5cf...</td>\n",
       "      <td>/data/train/20200413/vK2bLRNzllXNeyOMudnNSL5cf...</td>\n",
       "      <td>/data/train/20200413/vK2bLRNzllXNeyOMudnNSL5cf...</td>\n",
       "      <td>/data/train/20200413/vK2bLRNzllXNeyOMudnNSL5cf...</td>\n",
       "      <td>/data/train/20200413/vK2bLRNzllXNeyOMudnNSL5cf...</td>\n",
       "      <td>/data/train/20200413/vK2bLRNzllXNeyOMudnNSL5cf...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bjA2KpSxneNskrLBeqi4bqoTDQl2</td>\n",
       "      <td>India</td>\n",
       "      <td>72</td>\n",
       "      <td>healthy</td>\n",
       "      <td>Y</td>\n",
       "      <td>M</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>Thane</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>/data/train/20200413/bjA2KpSxneNskrLBeqi4bqoTD...</td>\n",
       "      <td>/data/train/20200413/bjA2KpSxneNskrLBeqi4bqoTD...</td>\n",
       "      <td>/data/train/20200413/bjA2KpSxneNskrLBeqi4bqoTD...</td>\n",
       "      <td>/data/train/20200413/bjA2KpSxneNskrLBeqi4bqoTD...</td>\n",
       "      <td>/data/train/20200413/bjA2KpSxneNskrLBeqi4bqoTD...</td>\n",
       "      <td>/data/train/20200413/bjA2KpSxneNskrLBeqi4bqoTD...</td>\n",
       "      <td>/data/train/20200413/bjA2KpSxneNskrLBeqi4bqoTD...</td>\n",
       "      <td>/data/train/20200413/bjA2KpSxneNskrLBeqi4bqoTD...</td>\n",
       "      <td>/data/train/20200413/bjA2KpSxneNskrLBeqi4bqoTD...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FSzobvJqOXf0rI6X05cHqOiU9Mu2</td>\n",
       "      <td>India</td>\n",
       "      <td>54</td>\n",
       "      <td>healthy</td>\n",
       "      <td>Y</td>\n",
       "      <td>M</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>Thane West</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>/data/train/20200413/FSzobvJqOXf0rI6X05cHqOiU9...</td>\n",
       "      <td>/data/train/20200413/FSzobvJqOXf0rI6X05cHqOiU9...</td>\n",
       "      <td>/data/train/20200413/FSzobvJqOXf0rI6X05cHqOiU9...</td>\n",
       "      <td>/data/train/20200413/FSzobvJqOXf0rI6X05cHqOiU9...</td>\n",
       "      <td>/data/train/20200413/FSzobvJqOXf0rI6X05cHqOiU9...</td>\n",
       "      <td>/data/train/20200413/FSzobvJqOXf0rI6X05cHqOiU9...</td>\n",
       "      <td>/data/train/20200413/FSzobvJqOXf0rI6X05cHqOiU9...</td>\n",
       "      <td>/data/train/20200413/FSzobvJqOXf0rI6X05cHqOiU9...</td>\n",
       "      <td>/data/train/20200413/FSzobvJqOXf0rI6X05cHqOiU9...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EqDWckxbsETyHUeBLQ8jLtxlhir2</td>\n",
       "      <td>India</td>\n",
       "      <td>31</td>\n",
       "      <td>healthy</td>\n",
       "      <td>Y</td>\n",
       "      <td>M</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>/data/train/20200413/EqDWckxbsETyHUeBLQ8jLtxlh...</td>\n",
       "      <td>/data/train/20200413/EqDWckxbsETyHUeBLQ8jLtxlh...</td>\n",
       "      <td>/data/train/20200413/EqDWckxbsETyHUeBLQ8jLtxlh...</td>\n",
       "      <td>/data/train/20200413/EqDWckxbsETyHUeBLQ8jLtxlh...</td>\n",
       "      <td>/data/train/20200413/EqDWckxbsETyHUeBLQ8jLtxlh...</td>\n",
       "      <td>/data/train/20200413/EqDWckxbsETyHUeBLQ8jLtxlh...</td>\n",
       "      <td>/data/train/20200413/EqDWckxbsETyHUeBLQ8jLtxlh...</td>\n",
       "      <td>/data/train/20200413/EqDWckxbsETyHUeBLQ8jLtxlh...</td>\n",
       "      <td>/data/train/20200413/EqDWckxbsETyHUeBLQ8jLtxlh...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FGRDO4IBbAejR0WHD5YbkXTCasg2</td>\n",
       "      <td>India</td>\n",
       "      <td>26</td>\n",
       "      <td>healthy</td>\n",
       "      <td>Y</td>\n",
       "      <td>M</td>\n",
       "      <td>Haryana</td>\n",
       "      <td>gurgaon</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>/data/train/20200413/FGRDO4IBbAejR0WHD5YbkXTCa...</td>\n",
       "      <td>/data/train/20200413/FGRDO4IBbAejR0WHD5YbkXTCa...</td>\n",
       "      <td>/data/train/20200413/FGRDO4IBbAejR0WHD5YbkXTCa...</td>\n",
       "      <td>/data/train/20200413/FGRDO4IBbAejR0WHD5YbkXTCa...</td>\n",
       "      <td>/data/train/20200413/FGRDO4IBbAejR0WHD5YbkXTCa...</td>\n",
       "      <td>/data/train/20200413/FGRDO4IBbAejR0WHD5YbkXTCa...</td>\n",
       "      <td>/data/train/20200413/FGRDO4IBbAejR0WHD5YbkXTCa...</td>\n",
       "      <td>/data/train/20200413/FGRDO4IBbAejR0WHD5YbkXTCa...</td>\n",
       "      <td>/data/train/20200413/FGRDO4IBbAejR0WHD5YbkXTCa...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        USER_ID COUNTRY  AGE COVID_STATUS ENGLISH_PROFICIENCY  \\\n",
       "0  vK2bLRNzllXNeyOMudnNSL5cfpG2   India   24      healthy                   Y   \n",
       "1  bjA2KpSxneNskrLBeqi4bqoTDQl2   India   72      healthy                   Y   \n",
       "2  FSzobvJqOXf0rI6X05cHqOiU9Mu2   India   54      healthy                   Y   \n",
       "3  EqDWckxbsETyHUeBLQ8jLtxlhir2   India   31      healthy                   Y   \n",
       "4  FGRDO4IBbAejR0WHD5YbkXTCasg2   India   26      healthy                   Y   \n",
       "\n",
       "  GENDER COUNTY_RO_STATE CITY_LOCALITY  Diabetes  Asthma  ...  \\\n",
       "0      M       Karnataka     Bangalore         0       0  ...   \n",
       "1      M     Maharashtra         Thane         0       0  ...   \n",
       "2      M     Maharashtra    Thane West         0       0  ...   \n",
       "3      M       Karnataka     Bangalore         0       0  ...   \n",
       "4      M         Haryana       gurgaon         0       0  ...   \n",
       "\n",
       "                                      breathing-deep  \\\n",
       "0  /data/train/20200413/vK2bLRNzllXNeyOMudnNSL5cf...   \n",
       "1  /data/train/20200413/bjA2KpSxneNskrLBeqi4bqoTD...   \n",
       "2  /data/train/20200413/FSzobvJqOXf0rI6X05cHqOiU9...   \n",
       "3  /data/train/20200413/EqDWckxbsETyHUeBLQ8jLtxlh...   \n",
       "4  /data/train/20200413/FGRDO4IBbAejR0WHD5YbkXTCa...   \n",
       "\n",
       "                                   breathing-shallow  \\\n",
       "0  /data/train/20200413/vK2bLRNzllXNeyOMudnNSL5cf...   \n",
       "1  /data/train/20200413/bjA2KpSxneNskrLBeqi4bqoTD...   \n",
       "2  /data/train/20200413/FSzobvJqOXf0rI6X05cHqOiU9...   \n",
       "3  /data/train/20200413/EqDWckxbsETyHUeBLQ8jLtxlh...   \n",
       "4  /data/train/20200413/FGRDO4IBbAejR0WHD5YbkXTCa...   \n",
       "\n",
       "                                         cough-heavy  \\\n",
       "0  /data/train/20200413/vK2bLRNzllXNeyOMudnNSL5cf...   \n",
       "1  /data/train/20200413/bjA2KpSxneNskrLBeqi4bqoTD...   \n",
       "2  /data/train/20200413/FSzobvJqOXf0rI6X05cHqOiU9...   \n",
       "3  /data/train/20200413/EqDWckxbsETyHUeBLQ8jLtxlh...   \n",
       "4  /data/train/20200413/FGRDO4IBbAejR0WHD5YbkXTCa...   \n",
       "\n",
       "                                       cough-shallow  \\\n",
       "0  /data/train/20200413/vK2bLRNzllXNeyOMudnNSL5cf...   \n",
       "1  /data/train/20200413/bjA2KpSxneNskrLBeqi4bqoTD...   \n",
       "2  /data/train/20200413/FSzobvJqOXf0rI6X05cHqOiU9...   \n",
       "3  /data/train/20200413/EqDWckxbsETyHUeBLQ8jLtxlh...   \n",
       "4  /data/train/20200413/FGRDO4IBbAejR0WHD5YbkXTCa...   \n",
       "\n",
       "                                       counting-fast  \\\n",
       "0  /data/train/20200413/vK2bLRNzllXNeyOMudnNSL5cf...   \n",
       "1  /data/train/20200413/bjA2KpSxneNskrLBeqi4bqoTD...   \n",
       "2  /data/train/20200413/FSzobvJqOXf0rI6X05cHqOiU9...   \n",
       "3  /data/train/20200413/EqDWckxbsETyHUeBLQ8jLtxlh...   \n",
       "4  /data/train/20200413/FGRDO4IBbAejR0WHD5YbkXTCa...   \n",
       "\n",
       "                                     counting-normal  \\\n",
       "0  /data/train/20200413/vK2bLRNzllXNeyOMudnNSL5cf...   \n",
       "1  /data/train/20200413/bjA2KpSxneNskrLBeqi4bqoTD...   \n",
       "2  /data/train/20200413/FSzobvJqOXf0rI6X05cHqOiU9...   \n",
       "3  /data/train/20200413/EqDWckxbsETyHUeBLQ8jLtxlh...   \n",
       "4  /data/train/20200413/FGRDO4IBbAejR0WHD5YbkXTCa...   \n",
       "\n",
       "                                             vowel-a  \\\n",
       "0  /data/train/20200413/vK2bLRNzllXNeyOMudnNSL5cf...   \n",
       "1  /data/train/20200413/bjA2KpSxneNskrLBeqi4bqoTD...   \n",
       "2  /data/train/20200413/FSzobvJqOXf0rI6X05cHqOiU9...   \n",
       "3  /data/train/20200413/EqDWckxbsETyHUeBLQ8jLtxlh...   \n",
       "4  /data/train/20200413/FGRDO4IBbAejR0WHD5YbkXTCa...   \n",
       "\n",
       "                                             vowel-e  \\\n",
       "0  /data/train/20200413/vK2bLRNzllXNeyOMudnNSL5cf...   \n",
       "1  /data/train/20200413/bjA2KpSxneNskrLBeqi4bqoTD...   \n",
       "2  /data/train/20200413/FSzobvJqOXf0rI6X05cHqOiU9...   \n",
       "3  /data/train/20200413/EqDWckxbsETyHUeBLQ8jLtxlh...   \n",
       "4  /data/train/20200413/FGRDO4IBbAejR0WHD5YbkXTCa...   \n",
       "\n",
       "                                             vowel-o  split  \n",
       "0  /data/train/20200413/vK2bLRNzllXNeyOMudnNSL5cf...    0.0  \n",
       "1  /data/train/20200413/bjA2KpSxneNskrLBeqi4bqoTD...    0.0  \n",
       "2  /data/train/20200413/FSzobvJqOXf0rI6X05cHqOiU9...    0.0  \n",
       "3  /data/train/20200413/EqDWckxbsETyHUeBLQ8jLtxlh...    0.0  \n",
       "4  /data/train/20200413/FGRDO4IBbAejR0WHD5YbkXTCa...    0.0  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "import cv2\r\n",
    "def preprocess_other(sample):\r\n",
    "  image_target_height, image_target_width = 64, 64 #setting up the shape of sample\r\n",
    "  audio_binary = tf.io.read_file(sample) #read-in the sample \r\n",
    "  audio, rate = tf.audio.decode_wav(audio_binary, desired_channels=1) #getting the audio and rate\r\n",
    "  #label = sample['label']\r\n",
    "\r\n",
    "  def py_preprocess_audio(audio):\r\n",
    "      audio = audio.numpy().astype('float32')\r\n",
    "\r\n",
    "      spectogram = librosa.feature.melspectrogram(\r\n",
    "        y=audio, n_fft=1024,  n_mels=64, hop_length=64, sr=8000, fmax=2000 #n_fft = window size, n_mels = frequency bins, hop_lenghth =jump to the right , sr = sound rate, fmax = \r\n",
    "      ) \r\n",
    "\r\n",
    "      spectogram /= np.max(spectogram) #devide by np.max(audio)\r\n",
    "      spectogram = cv2.resize(spectogram, dsize=(image_target_height, image_target_width))\r\n",
    "      spectogram = np.expand_dims(spectogram, axis=-1)\r\n",
    "      return spectogram\r\n",
    "\r\n",
    "  spectogram = tf.py_function(py_preprocess_audio, [audio], tf.float32)\r\n",
    "  spectogram.set_shape((image_target_height, image_target_width, 1))\r\n",
    "\r\n",
    "  return spectogram#, label"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "\r\n",
    "#test\r\n",
    "path = './CoronaHack-Respiratory-Sound-Dataset' + df_meta.loc[16,'counting-normal']\r\n",
    "#print(path)\r\n",
    "def pr(sample):\r\n",
    "    image_target_height, image_target_width = 64, 64 #setting up the shape of sample\r\n",
    "    audio_binary = tf.io.read_file(sample) #read-in the sample \r\n",
    "    audio, rate = tf.audio.decode_wav(audio_binary, desired_channels=1) #getting the audio and rate\r\n",
    "    #audio = audio[:,0]\r\n",
    "    #print(audio.shape)\r\n",
    "    return(audio)\r\n",
    "\r\n",
    "print(pr(path))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tf.Tensor(\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " ...\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]], shape=(864256, 1), dtype=float32)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "path_counnting_normal = df_meta2['counting-normal'].tolist()\r\n",
    "path_counnting_normal = ['./CoronaHack-Respiratory-Sound-Dataset' + dir_name for dir_name in path_counnting_normal]\r\n",
    "#labels = tf.convert_to_tensor()\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "# Convert to Tensor\r\n",
    "sound_paths_counnting_normal = tf.convert_to_tensor(path_counnting_normal, dtype=tf.string)\r\n",
    "# Build a TF Queue, shuffle data\r\n",
    "#sound,labels = tf.data.Dataset.from_tensor_slices([sound_paths_counnting_normal, labels])\r\n",
    "#make tensor slices and map in batches of 32\r\n",
    "sound = tf.data.Dataset.from_tensor_slices(sound_paths_counnting_normal)\r\n",
    "x = sound.map(lambda sample: preprocess_other(sample)).batch(32)\r\n",
    "x"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<BatchDataset shapes: (None, 64, 64, 1), types: tf.float32>"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "source": [
    "names = ['counting-normal','counting-fast']\r\n",
    "input_dic = {}\r\n",
    "for index,name in enumerate(names):\r\n",
    "    path_list = df_meta2[name].tolist()\r\n",
    "    path_name = ['./CoronaHack-Respiratory-Sound-Dataset'  + dir_name for dir_name in path_list]\r\n",
    "    sound_paths_tensor = tf.convert_to_tensor(path_name, dtype=tf.string)\r\n",
    "    sound = tf.data.Dataset.from_tensor_slices(sound_paths_tensor)\r\n",
    "    input_dic['x_{}'.format(index)] = sound.map(lambda sample: preprocess_other(sample)).batch(32)\r\n",
    "input_dic"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'x_0': <BatchDataset shapes: (None, 64, 64, 1), types: tf.float32>,\n",
       " 'x_1': <BatchDataset shapes: (None, 64, 64, 1), types: tf.float32>}"
      ]
     },
     "metadata": {},
     "execution_count": 41
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "def wav_to_mel(file_path):\r\n",
    "    image_target_height, image_target_width = 64, 64\r\n",
    "    audio_binary = tf.io.read_file(file_path)\r\n",
    "    audio, rate = tf.audio.decode_wav(audio_binary, desired_channels=1)\r\n",
    "    #waveform = tf.squeeze(audio, axis=-1)\r\n",
    "    audio = audio[:,0]\r\n",
    "    print(audio.shape)\r\n",
    "    position = tfio.audio.trim(audio, axis=0, epsilon=0.1)\r\n",
    "    print(position[0])\r\n",
    "    start = position[0]\r\n",
    "    end = position[1]\r\n",
    "    audio= audio[start:end]\r\n",
    "\r\n",
    "    # Normalize audio data\r\n",
    "    audio = tf.cast(audio, tf.float32) / 32768.0  # Max int for audio data\r\n",
    "    # Create the spectogram from audio data\r\n",
    "    spectrogram = tfio.audio.spectrogram(\r\n",
    "        audio, nfft=1024, window=128, stride=64\r\n",
    "    )\r\n",
    "    # Turn spectrogram into mel spectrogram\r\n",
    "    spectrogram = tfio.audio.melscale(\r\n",
    "        spectrogram, rate=rate, mels=64, fmin=0, fmax=2000\r\n",
    "    )\r\n",
    "\r\n",
    "    #spectrogram /= np.max(audio)\r\n",
    "    spectrogram /= tf.math.reduce_max(spectrogram) # Normalize\r\n",
    "    spectrogram = tf.expand_dims(spectrogram, axis=-1) # 2D -> 3D\r\n",
    "    spectrogram = tf.image.resize(spectrogram, (image_target_height, image_target_width)) # Resize the picture\r\n",
    "    spectrogram = tf.transpose(spectrogram, perm=(1, 0, 2)) # Swap the first two axis\r\n",
    "    spectrogram = spectrogram[::-1, :, :] # Flip the first axis (frequency)\r\n",
    "\r\n",
    "    #display(Audio(audio, rate=8000))\r\n",
    "   \r\n",
    "    return spectrogram\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "import tensorflow_io as tfio\r\n",
    "from IPython.display import Audio, display\r\n",
    "\r\n",
    "sounds = ['counting-fast','counting-normal']\r\n",
    "spects = {}\r\n",
    "# initialize with empty list\r\n",
    "for i in range(len(df_meta2)):\r\n",
    "        spects[i] = []\r\n",
    "# create spect for each sound\r\n",
    "for sound in sounds:\r\n",
    "    for i in range(len(df_meta2)):\r\n",
    "        path = './CoronaHack-Respiratory-Sound-Dataset' + df_meta2.loc[i,sound]\r\n",
    "        spects[i].append(preprocess_other(path))\r\n",
    "\r\n",
    "#spects   \r\n",
    "print(spects)\r\n"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "UnknownError",
     "evalue": "ParameterError: Invalid shape for monophonic audio: ndim=2, shape=(196608, 1)\nTraceback (most recent call last):\n\n  File \"C:\\Users\\paulg\\.conda\\envs\\corona\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 247, in __call__\n    return func(device, token, args)\n\n  File \"C:\\Users\\paulg\\.conda\\envs\\corona\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 135, in __call__\n    ret = self._func(*args)\n\n  File \"C:\\Users\\paulg\\.conda\\envs\\corona\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 645, in wrapper\n    return func(*args, **kwargs)\n\n  File \"<ipython-input-10-867061280308>\", line 12, in py_preprocess_audio\n    y=audio, n_fft=1024,  n_mels=64, hop_length=64, sr=8000, fmax=2000 #n_fft = window size, n_mels = frequency bins, hop_lenghth =jump to the right , sr = sound rate, fmax =\n\n  File \"C:\\Users\\paulg\\.conda\\envs\\corona\\lib\\site-packages\\librosa\\feature\\spectral.py\", line 2004, in melspectrogram\n    pad_mode=pad_mode,\n\n  File \"C:\\Users\\paulg\\.conda\\envs\\corona\\lib\\site-packages\\librosa\\core\\spectrum.py\", line 2519, in _spectrogram\n    pad_mode=pad_mode,\n\n  File \"C:\\Users\\paulg\\.conda\\envs\\corona\\lib\\site-packages\\librosa\\core\\spectrum.py\", line 217, in stft\n    util.valid_audio(y)\n\n  File \"C:\\Users\\paulg\\.conda\\envs\\corona\\lib\\site-packages\\librosa\\util\\utils.py\", line 295, in valid_audio\n    \"ndim={:d}, shape={}\".format(y.ndim, y.shape)\n\nlibrosa.util.exceptions.ParameterError: Invalid shape for monophonic audio: ndim=2, shape=(196608, 1)\n\n [Op:EagerPyFunc]",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-9ea5f79d9d9f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_meta2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'./CoronaHack-Respiratory-Sound-Dataset'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdf_meta2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msound\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[0mspects\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreprocess_other\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;31m#spects\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-867061280308>\u001b[0m in \u001b[0;36mpreprocess_other\u001b[1;34m(sample)\u001b[0m\n\u001b[0;32m     18\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mspectogram\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m   \u001b[0mspectogram\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpy_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpy_preprocess_audio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0maudio\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m   \u001b[0mspectogram\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_target_height\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage_target_width\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\corona\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    204\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\corona\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\u001b[0m in \u001b[0;36meager_py_func\u001b[1;34m(func, inp, Tout, name)\u001b[0m\n\u001b[0;32m    511\u001b[0m   \"\"\"\n\u001b[0;32m    512\u001b[0m   return _eager_py_func(\n\u001b[1;32m--> 513\u001b[1;33m       func=func, inp=inp, Tout=Tout, name=name, use_tape_cache=True)\n\u001b[0m\u001b[0;32m    514\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    515\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\corona\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\u001b[0m in \u001b[0;36m_eager_py_func\u001b[1;34m(func, inp, Tout, name, use_tape_cache)\u001b[0m\n\u001b[0;32m    418\u001b[0m           \u001b[0meager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    419\u001b[0m           \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 420\u001b[1;33m           use_tape_cache=use_tape_cache)\n\u001b[0m\u001b[0;32m    421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    422\u001b[0m   return _internal_py_func(\n",
      "\u001b[1;32m~\\.conda\\envs\\corona\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\u001b[0m in \u001b[0;36m_internal_py_func\u001b[1;34m(func, inp, Tout, stateful, eager, is_grad_func, name, use_tape_cache)\u001b[0m\n\u001b[0;32m    346\u001b[0m         \u001b[0mis_async\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m         \u001b[0mTout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTout\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 348\u001b[1;33m         name=name)\n\u001b[0m\u001b[0;32m    349\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    350\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mstateful\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\corona\\lib\\site-packages\\tensorflow\\python\\ops\\gen_script_ops.py\u001b[0m in \u001b[0;36meager_py_func\u001b[1;34m(input, token, Tout, is_async, name)\u001b[0m\n\u001b[0;32m     46\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m       \u001b[0m_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m       \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\corona\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   6939\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\" name: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6940\u001b[0m   \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6941\u001b[1;33m   \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6942\u001b[0m   \u001b[1;31m# pylint: enable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6943\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\corona\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mUnknownError\u001b[0m: ParameterError: Invalid shape for monophonic audio: ndim=2, shape=(196608, 1)\nTraceback (most recent call last):\n\n  File \"C:\\Users\\paulg\\.conda\\envs\\corona\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 247, in __call__\n    return func(device, token, args)\n\n  File \"C:\\Users\\paulg\\.conda\\envs\\corona\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 135, in __call__\n    ret = self._func(*args)\n\n  File \"C:\\Users\\paulg\\.conda\\envs\\corona\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 645, in wrapper\n    return func(*args, **kwargs)\n\n  File \"<ipython-input-10-867061280308>\", line 12, in py_preprocess_audio\n    y=audio, n_fft=1024,  n_mels=64, hop_length=64, sr=8000, fmax=2000 #n_fft = window size, n_mels = frequency bins, hop_lenghth =jump to the right , sr = sound rate, fmax =\n\n  File \"C:\\Users\\paulg\\.conda\\envs\\corona\\lib\\site-packages\\librosa\\feature\\spectral.py\", line 2004, in melspectrogram\n    pad_mode=pad_mode,\n\n  File \"C:\\Users\\paulg\\.conda\\envs\\corona\\lib\\site-packages\\librosa\\core\\spectrum.py\", line 2519, in _spectrogram\n    pad_mode=pad_mode,\n\n  File \"C:\\Users\\paulg\\.conda\\envs\\corona\\lib\\site-packages\\librosa\\core\\spectrum.py\", line 217, in stft\n    util.valid_audio(y)\n\n  File \"C:\\Users\\paulg\\.conda\\envs\\corona\\lib\\site-packages\\librosa\\util\\utils.py\", line 295, in valid_audio\n    \"ndim={:d}, shape={}\".format(y.ndim, y.shape)\n\nlibrosa.util.exceptions.ParameterError: Invalid shape for monophonic audio: ndim=2, shape=(196608, 1)\n\n [Op:EagerPyFunc]"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    " !pip install pydub tensorflow_io"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: pydub in c:\\users\\paulg\\.conda\\envs\\corona\\lib\\site-packages (0.25.1)\n",
      "Collecting tensorflow_io\n",
      "  Downloading tensorflow_io-0.21.0-cp36-cp36m-win_amd64.whl (21.3 MB)\n",
      "Requirement already satisfied: tensorflow<2.7.0,>=2.6.0 in c:\\users\\paulg\\.conda\\envs\\corona\\lib\\site-packages (from tensorflow_io) (2.6.0)\n",
      "Collecting tensorflow-io-gcs-filesystem==0.21.0\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.21.0-cp36-cp36m-win_amd64.whl (1.5 MB)\n",
      "Requirement already satisfied: tensorboard~=2.6 in c:\\users\\paulg\\.conda\\envs\\corona\\lib\\site-packages (from tensorflow<2.7.0,>=2.6.0->tensorflow_io) (2.6.0)\n",
      "Requirement already satisfied: absl-py~=0.10 in c:\\users\\paulg\\.conda\\envs\\corona\\lib\\site-packages (from tensorflow<2.7.0,>=2.6.0->tensorflow_io) (0.13.0)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in c:\\users\\paulg\\.conda\\envs\\corona\\lib\\site-packages (from tensorflow<2.7.0,>=2.6.0->tensorflow_io) (1.6.3)\n",
      "Requirement already satisfied: numpy~=1.19.2 in c:\\users\\paulg\\.conda\\envs\\corona\\lib\\site-packages (from tensorflow<2.7.0,>=2.6.0->tensorflow_io) (1.19.5)\n",
      "Requirement already satisfied: google-pasta~=0.2 in c:\\users\\paulg\\.conda\\envs\\corona\\lib\\site-packages (from tensorflow<2.7.0,>=2.6.0->tensorflow_io) (0.2.0)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in c:\\users\\paulg\\.conda\\envs\\corona\\lib\\site-packages (from tensorflow<2.7.0,>=2.6.0->tensorflow_io) (3.3.0)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in c:\\users\\paulg\\.conda\\envs\\corona\\lib\\site-packages (from tensorflow<2.7.0,>=2.6.0->tensorflow_io) (1.1.0)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in c:\\users\\paulg\\.conda\\envs\\corona\\lib\\site-packages (from tensorflow<2.7.0,>=2.6.0->tensorflow_io) (1.12.1)\n",
      "Requirement already satisfied: tensorflow-estimator~=2.6 in c:\\users\\paulg\\.conda\\envs\\corona\\lib\\site-packages (from tensorflow<2.7.0,>=2.6.0->tensorflow_io) (2.6.0)\n",
      "Requirement already satisfied: gast==0.4.0 in c:\\users\\paulg\\.conda\\envs\\corona\\lib\\site-packages (from tensorflow<2.7.0,>=2.6.0->tensorflow_io) (0.4.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in c:\\users\\paulg\\.conda\\envs\\corona\\lib\\site-packages (from tensorflow<2.7.0,>=2.6.0->tensorflow_io) (3.18.0)\n",
      "Requirement already satisfied: six~=1.15.0 in c:\\users\\paulg\\.conda\\envs\\corona\\lib\\site-packages (from tensorflow<2.7.0,>=2.6.0->tensorflow_io) (1.15.0)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in c:\\users\\paulg\\.conda\\envs\\corona\\lib\\site-packages (from tensorflow<2.7.0,>=2.6.0->tensorflow_io) (3.7.4.3)\n",
      "Requirement already satisfied: wheel~=0.35 in c:\\users\\paulg\\.conda\\envs\\corona\\lib\\site-packages (from tensorflow<2.7.0,>=2.6.0->tensorflow_io) (0.37.0)\n",
      "Requirement already satisfied: keras~=2.6 in c:\\users\\paulg\\.conda\\envs\\corona\\lib\\site-packages (from tensorflow<2.7.0,>=2.6.0->tensorflow_io) (2.6.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.37.0 in c:\\users\\paulg\\.conda\\envs\\corona\\lib\\site-packages (from tensorflow<2.7.0,>=2.6.0->tensorflow_io) (1.40.0)\n",
      "Requirement already satisfied: h5py~=3.1.0 in c:\\users\\paulg\\.conda\\envs\\corona\\lib\\site-packages (from tensorflow<2.7.0,>=2.6.0->tensorflow_io) (3.1.0)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in c:\\users\\paulg\\.conda\\envs\\corona\\lib\\site-packages (from tensorflow<2.7.0,>=2.6.0->tensorflow_io) (1.1.2)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in c:\\users\\paulg\\.conda\\envs\\corona\\lib\\site-packages (from tensorflow<2.7.0,>=2.6.0->tensorflow_io) (1.12)\n",
      "Requirement already satisfied: clang~=5.0 in c:\\users\\paulg\\.conda\\envs\\corona\\lib\\site-packages (from tensorflow<2.7.0,>=2.6.0->tensorflow_io) (5.0)\n",
      "Requirement already satisfied: cached-property in c:\\users\\paulg\\.conda\\envs\\corona\\lib\\site-packages (from h5py~=3.1.0->tensorflow<2.7.0,>=2.6.0->tensorflow_io) (1.5.2)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in c:\\users\\paulg\\.conda\\envs\\corona\\lib\\site-packages (from tensorboard~=2.6->tensorflow<2.7.0,>=2.6.0->tensorflow_io) (1.35.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\paulg\\.conda\\envs\\corona\\lib\\site-packages (from tensorboard~=2.6->tensorflow<2.7.0,>=2.6.0->tensorflow_io) (0.4.6)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\paulg\\.conda\\envs\\corona\\lib\\site-packages (from tensorboard~=2.6->tensorflow<2.7.0,>=2.6.0->tensorflow_io) (1.8.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\paulg\\.conda\\envs\\corona\\lib\\site-packages (from tensorboard~=2.6->tensorflow<2.7.0,>=2.6.0->tensorflow_io) (52.0.0.post20210125)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\paulg\\.conda\\envs\\corona\\lib\\site-packages (from tensorboard~=2.6->tensorflow<2.7.0,>=2.6.0->tensorflow_io) (2.0.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\paulg\\.conda\\envs\\corona\\lib\\site-packages (from tensorboard~=2.6->tensorflow<2.7.0,>=2.6.0->tensorflow_io) (0.6.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\paulg\\.conda\\envs\\corona\\lib\\site-packages (from tensorboard~=2.6->tensorflow<2.7.0,>=2.6.0->tensorflow_io) (3.3.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\paulg\\.conda\\envs\\corona\\lib\\site-packages (from tensorboard~=2.6->tensorflow<2.7.0,>=2.6.0->tensorflow_io) (2.26.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\paulg\\.conda\\envs\\corona\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow<2.7.0,>=2.6.0->tensorflow_io) (4.7.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\paulg\\.conda\\envs\\corona\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow<2.7.0,>=2.6.0->tensorflow_io) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\paulg\\.conda\\envs\\corona\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow<2.7.0,>=2.6.0->tensorflow_io) (4.2.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\paulg\\.conda\\envs\\corona\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow<2.7.0,>=2.6.0->tensorflow_io) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata in c:\\users\\paulg\\.conda\\envs\\corona\\lib\\site-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow<2.7.0,>=2.6.0->tensorflow_io) (4.6.4)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\paulg\\.conda\\envs\\corona\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow<2.7.0,>=2.6.0->tensorflow_io) (0.4.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\paulg\\.conda\\envs\\corona\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow<2.7.0,>=2.6.0->tensorflow_io) (2021.5.30)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\paulg\\.conda\\envs\\corona\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow<2.7.0,>=2.6.0->tensorflow_io) (3.2)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\paulg\\.conda\\envs\\corona\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow<2.7.0,>=2.6.0->tensorflow_io) (2.0.5)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\paulg\\.conda\\envs\\corona\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow<2.7.0,>=2.6.0->tensorflow_io) (1.26.6)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\paulg\\.conda\\envs\\corona\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow<2.7.0,>=2.6.0->tensorflow_io) (3.1.1)\n",
      "Requirement already satisfied: dataclasses in c:\\users\\paulg\\.conda\\envs\\corona\\lib\\site-packages (from werkzeug>=0.11.15->tensorboard~=2.6->tensorflow<2.7.0,>=2.6.0->tensorflow_io) (0.8)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\paulg\\.conda\\envs\\corona\\lib\\site-packages (from importlib-metadata->markdown>=2.6.8->tensorboard~=2.6->tensorflow<2.7.0,>=2.6.0->tensorflow_io) (3.5.0)\n",
      "Installing collected packages: tensorflow-io-gcs-filesystem, tensorflow-io\n",
      "Successfully installed tensorflow-io-0.21.0 tensorflow-io-gcs-filesystem-0.21.0\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#load data\r\n",
    "\r\n",
    "def load_data(data_directory):\r\n",
    "    directories = [d for d in os.listdir(data_directory) \r\n",
    "                   if os.path.isdir(os.path.join(data_directory, d))]\r\n",
    "    labels = []\r\n",
    "    sound = []\r\n",
    "    for d in directories:\r\n",
    "        label_directory = os.path.join(data_directory, d)\r\n",
    "        file_names = [os.path.join(label_directory, f) \r\n",
    "                      for f in os.listdir(label_directory) \r\n",
    "                      if f.endswith(\".wav\")]\r\n",
    "        for f in file_names:\r\n",
    "            images.append(skimage.data.imread(f))\r\n",
    "            labels.append(int(d))\r\n",
    "    return images, labels\r\n",
    "\r\n",
    "ROOT_PATH = \"/your/root/path\"\r\n",
    "train_data_directory = os.path.join(ROOT_PATH, \"./CoronaHack-Respiratory-Sound-Dataset/data/train\")\r\n",
    "test_data_directory = os.path.join(ROOT_PATH, \"./CoronaHack-Respiratory-Sound-Dataset/data/test\")\r\n",
    "\r\n",
    "images, labels = load_data(train_data_directory)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.6.13",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.13 64-bit ('corona': conda)"
  },
  "interpreter": {
   "hash": "8e06dae36da5af555d220c5b5d98ac2c0ea1251ccd3307154d7e0f059350ea4f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}