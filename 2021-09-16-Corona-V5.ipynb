{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Covid Project\r\n",
    "\r\n",
    "In this data science project we want to use data from the COWAS data base (uploaded at Kaggle: https://www.kaggle.com/praveengovi/coronahack-respiratory-sound-dataset) to make a \r\n",
    "\r\n",
    "\r\n",
    "### Data Structure\r\n",
    "\r\n",
    "There are 1397 cases of which 56 are positive ones. Each case is composed of 9 independing recordings \r\n",
    "['counting-normal','counting-fast','breathing-deep','breathing-shallow','cough-heavy','cough-shallow','vowel-a','vowel-e','vowel-o']\r\n",
    "\r\n",
    "### Potential Solution\r\n",
    "\r\n",
    "Using an auto-encoder approach (out of distribution), training on \"healthy\" cases.\r\n",
    "Proposed solution (https://github.com/moiseshorta/MelSpecVAE)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## #Chunk 1\r\n",
    "### Libraries"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "\r\n",
    "#Data visualization\r\n",
    "\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "import seaborn as sns\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "\r\n",
    "#Audio Analysis\r\n",
    "import glob\r\n",
    "import IPython\r\n",
    "import librosa\r\n",
    "import librosa.display\r\n",
    "import tensorflow as tf\r\n",
    "from tensorflow import keras\r\n",
    "\r\n",
    "#path\r\n",
    "import os\r\n",
    "\r\n",
    "#"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## #Chunk 2\r\n",
    "### Import Meta data (file path information)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# import meta data\r\n",
    "# Meta data csv contain different additional information about each case.\r\n",
    "# One column contains the path to the .wav files of each case\r\n",
    "df_meta = pd.read_csv('./CoronaHack-Respiratory-Sound-Dataset/Corona-Hack-Respiratory-Sound-Metadata.csv')\r\n",
    "df_meta.info(), df_meta.shape\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1397 entries, 0 to 1396\n",
      "Data columns (total 37 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   USER_ID                 1397 non-null   object \n",
      " 1   COUNTRY                 1397 non-null   object \n",
      " 2   AGE                     1397 non-null   int64  \n",
      " 3   COVID_STATUS            1396 non-null   object \n",
      " 4   ENGLISH_PROFICIENCY     1397 non-null   object \n",
      " 5   GENDER                  1397 non-null   object \n",
      " 6   COUNTY_RO_STATE         1397 non-null   object \n",
      " 7   CITY_LOCALITY           1228 non-null   object \n",
      " 8   Diabetes                1397 non-null   int64  \n",
      " 9   Asthma                  1397 non-null   int64  \n",
      " 10  Smoker                  1397 non-null   int64  \n",
      " 11  Hypertension            1397 non-null   int64  \n",
      " 12  Fever                   1397 non-null   int64  \n",
      " 13  Returning_User          1397 non-null   int64  \n",
      " 14  Using_Mask              1397 non-null   int64  \n",
      " 15  Cold                    1397 non-null   int64  \n",
      " 16  Caugh                   1397 non-null   int64  \n",
      " 17  Muscle_Pain             1397 non-null   int64  \n",
      " 18  loss_of_smell           1397 non-null   int64  \n",
      " 19  Sore_Throat             1397 non-null   int64  \n",
      " 20  Fatigue                 1397 non-null   int64  \n",
      " 21  Breathing_Difficulties  1397 non-null   int64  \n",
      " 22  Chronic_Lung_Disease    1397 non-null   int64  \n",
      " 23  Ischemic_Heart_Disease  1397 non-null   int64  \n",
      " 24  Pneumonia               1397 non-null   int64  \n",
      " 25  COVID_test_status       1355 non-null   float64\n",
      " 26  Diarrheoa               1397 non-null   int64  \n",
      " 27  DATES                   1397 non-null   int64  \n",
      " 28  breathing-deep          1396 non-null   object \n",
      " 29  breathing-shallow       1396 non-null   object \n",
      " 30  cough-heavy             1396 non-null   object \n",
      " 31  cough-shallow           1395 non-null   object \n",
      " 32  counting-fast           1397 non-null   object \n",
      " 33  counting-normal         1397 non-null   object \n",
      " 34  vowel-a                 1396 non-null   object \n",
      " 35  vowel-e                 1396 non-null   object \n",
      " 36  vowel-o                 1395 non-null   object \n",
      "dtypes: float64(1), int64(20), object(16)\n",
      "memory usage: 403.9+ KB\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(None, (1397, 37))"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "df_meta.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>USER_ID</th>\n",
       "      <th>COUNTRY</th>\n",
       "      <th>AGE</th>\n",
       "      <th>COVID_STATUS</th>\n",
       "      <th>ENGLISH_PROFICIENCY</th>\n",
       "      <th>GENDER</th>\n",
       "      <th>COUNTY_RO_STATE</th>\n",
       "      <th>CITY_LOCALITY</th>\n",
       "      <th>Diabetes</th>\n",
       "      <th>Asthma</th>\n",
       "      <th>...</th>\n",
       "      <th>DATES</th>\n",
       "      <th>breathing-deep</th>\n",
       "      <th>breathing-shallow</th>\n",
       "      <th>cough-heavy</th>\n",
       "      <th>cough-shallow</th>\n",
       "      <th>counting-fast</th>\n",
       "      <th>counting-normal</th>\n",
       "      <th>vowel-a</th>\n",
       "      <th>vowel-e</th>\n",
       "      <th>vowel-o</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vK2bLRNzllXNeyOMudnNSL5cfpG2</td>\n",
       "      <td>India</td>\n",
       "      <td>24</td>\n",
       "      <td>healthy</td>\n",
       "      <td>Y</td>\n",
       "      <td>M</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>20200413</td>\n",
       "      <td>/data/train/20200413/vK2bLRNzllXNeyOMudnNSL5cf...</td>\n",
       "      <td>/data/train/20200413/vK2bLRNzllXNeyOMudnNSL5cf...</td>\n",
       "      <td>/data/train/20200413/vK2bLRNzllXNeyOMudnNSL5cf...</td>\n",
       "      <td>/data/train/20200413/vK2bLRNzllXNeyOMudnNSL5cf...</td>\n",
       "      <td>/data/train/20200413/vK2bLRNzllXNeyOMudnNSL5cf...</td>\n",
       "      <td>/data/train/20200413/vK2bLRNzllXNeyOMudnNSL5cf...</td>\n",
       "      <td>/data/train/20200413/vK2bLRNzllXNeyOMudnNSL5cf...</td>\n",
       "      <td>/data/train/20200413/vK2bLRNzllXNeyOMudnNSL5cf...</td>\n",
       "      <td>/data/train/20200413/vK2bLRNzllXNeyOMudnNSL5cf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bjA2KpSxneNskrLBeqi4bqoTDQl2</td>\n",
       "      <td>India</td>\n",
       "      <td>72</td>\n",
       "      <td>healthy</td>\n",
       "      <td>Y</td>\n",
       "      <td>M</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>Thane</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>20200413</td>\n",
       "      <td>/data/train/20200413/bjA2KpSxneNskrLBeqi4bqoTD...</td>\n",
       "      <td>/data/train/20200413/bjA2KpSxneNskrLBeqi4bqoTD...</td>\n",
       "      <td>/data/train/20200413/bjA2KpSxneNskrLBeqi4bqoTD...</td>\n",
       "      <td>/data/train/20200413/bjA2KpSxneNskrLBeqi4bqoTD...</td>\n",
       "      <td>/data/train/20200413/bjA2KpSxneNskrLBeqi4bqoTD...</td>\n",
       "      <td>/data/train/20200413/bjA2KpSxneNskrLBeqi4bqoTD...</td>\n",
       "      <td>/data/train/20200413/bjA2KpSxneNskrLBeqi4bqoTD...</td>\n",
       "      <td>/data/train/20200413/bjA2KpSxneNskrLBeqi4bqoTD...</td>\n",
       "      <td>/data/train/20200413/bjA2KpSxneNskrLBeqi4bqoTD...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FSzobvJqOXf0rI6X05cHqOiU9Mu2</td>\n",
       "      <td>India</td>\n",
       "      <td>54</td>\n",
       "      <td>healthy</td>\n",
       "      <td>Y</td>\n",
       "      <td>M</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>Thane West</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>20200413</td>\n",
       "      <td>/data/train/20200413/FSzobvJqOXf0rI6X05cHqOiU9...</td>\n",
       "      <td>/data/train/20200413/FSzobvJqOXf0rI6X05cHqOiU9...</td>\n",
       "      <td>/data/train/20200413/FSzobvJqOXf0rI6X05cHqOiU9...</td>\n",
       "      <td>/data/train/20200413/FSzobvJqOXf0rI6X05cHqOiU9...</td>\n",
       "      <td>/data/train/20200413/FSzobvJqOXf0rI6X05cHqOiU9...</td>\n",
       "      <td>/data/train/20200413/FSzobvJqOXf0rI6X05cHqOiU9...</td>\n",
       "      <td>/data/train/20200413/FSzobvJqOXf0rI6X05cHqOiU9...</td>\n",
       "      <td>/data/train/20200413/FSzobvJqOXf0rI6X05cHqOiU9...</td>\n",
       "      <td>/data/train/20200413/FSzobvJqOXf0rI6X05cHqOiU9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EqDWckxbsETyHUeBLQ8jLtxlhir2</td>\n",
       "      <td>India</td>\n",
       "      <td>31</td>\n",
       "      <td>healthy</td>\n",
       "      <td>Y</td>\n",
       "      <td>M</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>20200413</td>\n",
       "      <td>/data/train/20200413/EqDWckxbsETyHUeBLQ8jLtxlh...</td>\n",
       "      <td>/data/train/20200413/EqDWckxbsETyHUeBLQ8jLtxlh...</td>\n",
       "      <td>/data/train/20200413/EqDWckxbsETyHUeBLQ8jLtxlh...</td>\n",
       "      <td>/data/train/20200413/EqDWckxbsETyHUeBLQ8jLtxlh...</td>\n",
       "      <td>/data/train/20200413/EqDWckxbsETyHUeBLQ8jLtxlh...</td>\n",
       "      <td>/data/train/20200413/EqDWckxbsETyHUeBLQ8jLtxlh...</td>\n",
       "      <td>/data/train/20200413/EqDWckxbsETyHUeBLQ8jLtxlh...</td>\n",
       "      <td>/data/train/20200413/EqDWckxbsETyHUeBLQ8jLtxlh...</td>\n",
       "      <td>/data/train/20200413/EqDWckxbsETyHUeBLQ8jLtxlh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FGRDO4IBbAejR0WHD5YbkXTCasg2</td>\n",
       "      <td>India</td>\n",
       "      <td>26</td>\n",
       "      <td>healthy</td>\n",
       "      <td>Y</td>\n",
       "      <td>M</td>\n",
       "      <td>Haryana</td>\n",
       "      <td>gurgaon</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>20200413</td>\n",
       "      <td>/data/train/20200413/FGRDO4IBbAejR0WHD5YbkXTCa...</td>\n",
       "      <td>/data/train/20200413/FGRDO4IBbAejR0WHD5YbkXTCa...</td>\n",
       "      <td>/data/train/20200413/FGRDO4IBbAejR0WHD5YbkXTCa...</td>\n",
       "      <td>/data/train/20200413/FGRDO4IBbAejR0WHD5YbkXTCa...</td>\n",
       "      <td>/data/train/20200413/FGRDO4IBbAejR0WHD5YbkXTCa...</td>\n",
       "      <td>/data/train/20200413/FGRDO4IBbAejR0WHD5YbkXTCa...</td>\n",
       "      <td>/data/train/20200413/FGRDO4IBbAejR0WHD5YbkXTCa...</td>\n",
       "      <td>/data/train/20200413/FGRDO4IBbAejR0WHD5YbkXTCa...</td>\n",
       "      <td>/data/train/20200413/FGRDO4IBbAejR0WHD5YbkXTCa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        USER_ID COUNTRY  AGE COVID_STATUS ENGLISH_PROFICIENCY  \\\n",
       "0  vK2bLRNzllXNeyOMudnNSL5cfpG2   India   24      healthy                   Y   \n",
       "1  bjA2KpSxneNskrLBeqi4bqoTDQl2   India   72      healthy                   Y   \n",
       "2  FSzobvJqOXf0rI6X05cHqOiU9Mu2   India   54      healthy                   Y   \n",
       "3  EqDWckxbsETyHUeBLQ8jLtxlhir2   India   31      healthy                   Y   \n",
       "4  FGRDO4IBbAejR0WHD5YbkXTCasg2   India   26      healthy                   Y   \n",
       "\n",
       "  GENDER COUNTY_RO_STATE CITY_LOCALITY  Diabetes  Asthma  ...     DATES  \\\n",
       "0      M       Karnataka     Bangalore         0       0  ...  20200413   \n",
       "1      M     Maharashtra         Thane         0       0  ...  20200413   \n",
       "2      M     Maharashtra    Thane West         0       0  ...  20200413   \n",
       "3      M       Karnataka     Bangalore         0       0  ...  20200413   \n",
       "4      M         Haryana       gurgaon         0       0  ...  20200413   \n",
       "\n",
       "                                      breathing-deep  \\\n",
       "0  /data/train/20200413/vK2bLRNzllXNeyOMudnNSL5cf...   \n",
       "1  /data/train/20200413/bjA2KpSxneNskrLBeqi4bqoTD...   \n",
       "2  /data/train/20200413/FSzobvJqOXf0rI6X05cHqOiU9...   \n",
       "3  /data/train/20200413/EqDWckxbsETyHUeBLQ8jLtxlh...   \n",
       "4  /data/train/20200413/FGRDO4IBbAejR0WHD5YbkXTCa...   \n",
       "\n",
       "                                   breathing-shallow  \\\n",
       "0  /data/train/20200413/vK2bLRNzllXNeyOMudnNSL5cf...   \n",
       "1  /data/train/20200413/bjA2KpSxneNskrLBeqi4bqoTD...   \n",
       "2  /data/train/20200413/FSzobvJqOXf0rI6X05cHqOiU9...   \n",
       "3  /data/train/20200413/EqDWckxbsETyHUeBLQ8jLtxlh...   \n",
       "4  /data/train/20200413/FGRDO4IBbAejR0WHD5YbkXTCa...   \n",
       "\n",
       "                                         cough-heavy  \\\n",
       "0  /data/train/20200413/vK2bLRNzllXNeyOMudnNSL5cf...   \n",
       "1  /data/train/20200413/bjA2KpSxneNskrLBeqi4bqoTD...   \n",
       "2  /data/train/20200413/FSzobvJqOXf0rI6X05cHqOiU9...   \n",
       "3  /data/train/20200413/EqDWckxbsETyHUeBLQ8jLtxlh...   \n",
       "4  /data/train/20200413/FGRDO4IBbAejR0WHD5YbkXTCa...   \n",
       "\n",
       "                                       cough-shallow  \\\n",
       "0  /data/train/20200413/vK2bLRNzllXNeyOMudnNSL5cf...   \n",
       "1  /data/train/20200413/bjA2KpSxneNskrLBeqi4bqoTD...   \n",
       "2  /data/train/20200413/FSzobvJqOXf0rI6X05cHqOiU9...   \n",
       "3  /data/train/20200413/EqDWckxbsETyHUeBLQ8jLtxlh...   \n",
       "4  /data/train/20200413/FGRDO4IBbAejR0WHD5YbkXTCa...   \n",
       "\n",
       "                                       counting-fast  \\\n",
       "0  /data/train/20200413/vK2bLRNzllXNeyOMudnNSL5cf...   \n",
       "1  /data/train/20200413/bjA2KpSxneNskrLBeqi4bqoTD...   \n",
       "2  /data/train/20200413/FSzobvJqOXf0rI6X05cHqOiU9...   \n",
       "3  /data/train/20200413/EqDWckxbsETyHUeBLQ8jLtxlh...   \n",
       "4  /data/train/20200413/FGRDO4IBbAejR0WHD5YbkXTCa...   \n",
       "\n",
       "                                     counting-normal  \\\n",
       "0  /data/train/20200413/vK2bLRNzllXNeyOMudnNSL5cf...   \n",
       "1  /data/train/20200413/bjA2KpSxneNskrLBeqi4bqoTD...   \n",
       "2  /data/train/20200413/FSzobvJqOXf0rI6X05cHqOiU9...   \n",
       "3  /data/train/20200413/EqDWckxbsETyHUeBLQ8jLtxlh...   \n",
       "4  /data/train/20200413/FGRDO4IBbAejR0WHD5YbkXTCa...   \n",
       "\n",
       "                                             vowel-a  \\\n",
       "0  /data/train/20200413/vK2bLRNzllXNeyOMudnNSL5cf...   \n",
       "1  /data/train/20200413/bjA2KpSxneNskrLBeqi4bqoTD...   \n",
       "2  /data/train/20200413/FSzobvJqOXf0rI6X05cHqOiU9...   \n",
       "3  /data/train/20200413/EqDWckxbsETyHUeBLQ8jLtxlh...   \n",
       "4  /data/train/20200413/FGRDO4IBbAejR0WHD5YbkXTCa...   \n",
       "\n",
       "                                             vowel-e  \\\n",
       "0  /data/train/20200413/vK2bLRNzllXNeyOMudnNSL5cf...   \n",
       "1  /data/train/20200413/bjA2KpSxneNskrLBeqi4bqoTD...   \n",
       "2  /data/train/20200413/FSzobvJqOXf0rI6X05cHqOiU9...   \n",
       "3  /data/train/20200413/EqDWckxbsETyHUeBLQ8jLtxlh...   \n",
       "4  /data/train/20200413/FGRDO4IBbAejR0WHD5YbkXTCa...   \n",
       "\n",
       "                                             vowel-o  \n",
       "0  /data/train/20200413/vK2bLRNzllXNeyOMudnNSL5cf...  \n",
       "1  /data/train/20200413/bjA2KpSxneNskrLBeqi4bqoTD...  \n",
       "2  /data/train/20200413/FSzobvJqOXf0rI6X05cHqOiU9...  \n",
       "3  /data/train/20200413/EqDWckxbsETyHUeBLQ8jLtxlh...  \n",
       "4  /data/train/20200413/FGRDO4IBbAejR0WHD5YbkXTCa...  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## #Chunk 3\r\n",
    "### Get the label for each case"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "#Get the label (healthy / COVID) \r\n",
    "\r\n",
    "#split COVID STATUS column to get labels in column 'split'\r\n",
    "df_meta['split'] = df_meta['COVID_STATUS'].str.split('_').str.get(0)\r\n",
    "#Check for NA\r\n",
    "df_meta.loc[:,'counting-normal'].isna().sum()\r\n",
    "df_meta.loc[:,'split'].value_counts()\r\n",
    "\r\n",
    "#Generate a dict to re-categorize the split column\r\n",
    "cat_dict = {'healthy':0,'no':0,'resp':0,'recovered':0,'positive':1}\r\n",
    "\r\n",
    "#map cat_dict to split column \r\n",
    "df_meta.loc[:,'split'] =  df_meta.loc[:,'split'].map(cat_dict)\r\n",
    "df_meta2 = df_meta.dropna(subset=['split'])\r\n",
    "df_meta2.loc[:,'split'] = df_meta2.loc[:,'split'].astype('int32')\r\n",
    "\r\n",
    "\r\n",
    "#Extract positive USER ID\r\n",
    "df_meta_positives = df_meta[df_meta['split'] == 1]\r\n",
    "df_meta_negatives = df_meta[df_meta['split'] == 0]\r\n",
    "\r\n",
    "positives = list(df_meta_positives['USER_ID'])\r\n",
    "negatives = list(df_meta_negatives['USER_ID'])\r\n",
    "len(positives),len(negatives)\r\n",
    "#positives"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\paulg\\.conda\\envs\\corona\\lib\\site-packages\\pandas\\core\\indexing.py:1745: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(ilocs[0], value)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(56, 1340)"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## #Chunk 5\r\n",
    "### generate Function to create the input data for auto-encoder"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "# Create function to load and prepare data for input \r\n",
    "# here we want to use the 9 recordings as separate features but grouped per case as input to the auto-encoder \r\n",
    "\r\n",
    "#names of 9 recordings per each case (extracted from the csv meta data file from )\r\n",
    "#names_input = ['counting-normal','counting-fast','breathing-deep','breathing-shallow','cough-heavy','cough-shallow','vowel-a','vowel-e','vowel-o']\r\n",
    "#label column from the meta data csv (#Chunk 3)\r\n",
    "name_label = 'split'\r\n",
    "\r\n",
    "def create_input_label(df=df_meta2,names=names_input,name_label=name_label):\r\n",
    "    input_dic = {} #Use a dictionnary to put in the 9 records per case\r\n",
    "    base_path = './CoronaHack-Respiratory-Sound-Dataset'\r\n",
    "    \r\n",
    "    for index,name in enumerate(names):\r\n",
    "        #print(index,name)\r\n",
    "        print(\"Create input run\")\r\n",
    "        path_list = df[name].tolist()\r\n",
    "        print(path_list[:10])\r\n",
    "        path_name = []\r\n",
    "        for dir_name in path_list:\r\n",
    "            path_name.append(base_path+str(dir_name))\r\n",
    "\r\n",
    "        print(path_name[:10])\r\n",
    "        print(\"Sound paths convert to tensor\")\r\n",
    "        sound_paths_tensor = tf.convert_to_tensor(path_name, dtype=tf.string) #convert to tensor\r\n",
    "\r\n",
    "        print(\"Sound PATH\", sound_paths_tensor[0])\r\n",
    "        print(\"Sound Dataset from tensor slices\")\r\n",
    "        sound = tf.data.Dataset.from_tensor_slices(sound_paths_tensor)\r\n",
    "        print(\"Sound PATH from slices\", sound[0])\r\n",
    "        #sound = tf.data.Dataset.from_generator(lambda sample: preprocess_other(sample).batch(32), output_types=tf.int32, output_shapes = (64,64,1),)\r\n",
    "        print(\"Calling preprocessing\")\r\n",
    "        print(\"SOUNDD\", sound)\r\n",
    "        input_dic['x_{}'.format(index)] = sound.map(lambda sample: preprocess_other(sample)) #generating the names of recordings(features x_0 till x_8) in batch mode\r\n",
    "\r\n",
    "\r\n",
    "    path_label = df[name_label]\r\n",
    "    #print(path_label)\r\n",
    "    y = tf.convert_to_tensor(path_label, dtype=tf.int16)\r\n",
    "\r\n",
    "    return input_dic,y\r\n",
    "\r\n",
    "    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "x,y = create_input_label()\r\n",
    "x = list(x.values())\r\n",
    "x"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Create input run\n",
      "['/data/train/20200413/vK2bLRNzllXNeyOMudnNSL5cfpG2/counting-normal.wav', '/data/train/20200413/bjA2KpSxneNskrLBeqi4bqoTDQl2/counting-normal.wav', '/data/train/20200413/FSzobvJqOXf0rI6X05cHqOiU9Mu2/counting-normal.wav', '/data/train/20200413/EqDWckxbsETyHUeBLQ8jLtxlhir2/counting-normal.wav', '/data/train/20200413/FGRDO4IBbAejR0WHD5YbkXTCasg2/counting-normal.wav', '/data/train/20200413/htQzROl26OWQpIYFDzv11F79PLR2/counting-normal.wav', '/data/train/20200413/pW9mCAeWYiMoM7wW7riLvNRbYDO2/counting-normal.wav', '/data/train/20200413/Eu11s84cuBTiPXTAtVf9mj3GkqA2/counting-normal.wav', '/data/train/20200413/L7S8iIPKgiO6QWLC3mGkROCMa0s1/counting-normal.wav', '/data/train/20200413/eP8gEM0KcBU6S5JpMdycX74KP3p2/counting-normal.wav']\n",
      "['./CoronaHack-Respiratory-Sound-Dataset/data/train/20200413/vK2bLRNzllXNeyOMudnNSL5cfpG2/counting-normal.wav', './CoronaHack-Respiratory-Sound-Dataset/data/train/20200413/bjA2KpSxneNskrLBeqi4bqoTDQl2/counting-normal.wav', './CoronaHack-Respiratory-Sound-Dataset/data/train/20200413/FSzobvJqOXf0rI6X05cHqOiU9Mu2/counting-normal.wav', './CoronaHack-Respiratory-Sound-Dataset/data/train/20200413/EqDWckxbsETyHUeBLQ8jLtxlhir2/counting-normal.wav', './CoronaHack-Respiratory-Sound-Dataset/data/train/20200413/FGRDO4IBbAejR0WHD5YbkXTCasg2/counting-normal.wav', './CoronaHack-Respiratory-Sound-Dataset/data/train/20200413/htQzROl26OWQpIYFDzv11F79PLR2/counting-normal.wav', './CoronaHack-Respiratory-Sound-Dataset/data/train/20200413/pW9mCAeWYiMoM7wW7riLvNRbYDO2/counting-normal.wav', './CoronaHack-Respiratory-Sound-Dataset/data/train/20200413/Eu11s84cuBTiPXTAtVf9mj3GkqA2/counting-normal.wav', './CoronaHack-Respiratory-Sound-Dataset/data/train/20200413/L7S8iIPKgiO6QWLC3mGkROCMa0s1/counting-normal.wav', './CoronaHack-Respiratory-Sound-Dataset/data/train/20200413/eP8gEM0KcBU6S5JpMdycX74KP3p2/counting-normal.wav']\n",
      "Sound paths convert to tensor\n",
      "Sound PATH tf.Tensor(b'./CoronaHack-Respiratory-Sound-Dataset/data/train/20200413/vK2bLRNzllXNeyOMudnNSL5cfpG2/counting-normal.wav', shape=(), dtype=string)\n",
      "Sound Dataset from tensor slices\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "'TensorSliceDataset' object does not support indexing",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-9571fd0bf905>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_input_label\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-29-8eccc6d9d23a>\u001b[0m in \u001b[0;36mcreate_input_label\u001b[1;34m(df, names, name_label)\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Sound Dataset from tensor slices\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[0msound\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_tensor_slices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msound_paths_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Sound PATH from slices\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msound\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m         \u001b[1;31m#sound = tf.data.Dataset.from_generator(lambda sample: preprocess_other(sample).batch(32), output_types=tf.int32, output_shapes = (64,64,1),)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Calling preprocessing\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'TensorSliceDataset' object does not support indexing"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## #Chunk 4\r\n",
    "### Define Function for .wav import and preprocessing "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# Write function for import and preprocessing of all 9 .wav files per case (code adapted from Tristan classes) \r\n",
    "\r\n",
    "import cv2\r\n",
    "def preprocess_other(sample):\r\n",
    "  print(\"Start preprocessing, setting up the shape of sample\")\r\n",
    "  print(\"Sample\", sample)\r\n",
    "  \r\n",
    "  audio = sample\r\n",
    "  #label = sample['label']\r\n",
    "  audio = tf.reshape(sample, [-1])\r\n",
    "        \r\n",
    "  \r\n",
    "  print(\"PY-PREPROCESS set audio file as float\", type(audio))\r\n",
    "  audio = tf.cast(audio, tf.float32) #set audio file as float\r\n",
    "  #audio = audio[24500:5000+len(audio)//10]\r\n",
    "  # Plot audio amplitude\r\n",
    "  # plt.figure(figsize=(10,15))\r\n",
    "  # plt.plot(audio)\r\n",
    "  # plt.show()\r\n",
    "  # plt.close()\r\n",
    "  \r\n",
    "  print(audio)\r\n",
    "  print(\"PY-PREPROCESS generate the mel spectrogram\")\r\n",
    "  #generate the mel spectrogram\r\n",
    "  spectrogram = tfio.audio.spectrogram( \r\n",
    "      audio, nfft=1024, window=1024, stride=64\r\n",
    "  )\r\n",
    "\r\n",
    "  spectrogram = tfio.audio.melscale(\r\n",
    "      spectrogram, rate=8000, mels=64, fmin=0, fmax=2000 #mels = bins, fmin,fmax = frequences\r\n",
    "  )\r\n",
    "\r\n",
    "  print(\"PY-PREPROCESS devide by np.max(audio)\")\r\n",
    "  spectrogram /= tf.math.reduce_max(spectrogram) #normalization\r\n",
    "  spectrogram = tf.expand_dims(spectrogram, axis=-1) #add dimension 2D -> 3D\r\n",
    "  spectrogram = tf.image.resize(spectrogram, (image_target_height, image_target_height)) #resize in two dimensions\r\n",
    "  spectrogram = tf.transpose(spectrogram, perm=(1, 0, 2)) #transpose the first two axis\r\n",
    "  spectrogram = spectrogram[::-1, :, :] #flip the first axis(frequency)\r\n",
    "\r\n",
    "  # plt.figure(figsize=(10,15))\r\n",
    "  # plt.imshow(spectrogram[::-1,:], cmap='inferno') #flipping upside down\r\n",
    "  # plt.show()\r\n",
    "  # plt.close()\r\n",
    "  \r\n",
    "  \r\n",
    "\r\n",
    "  # RESHAPE TO FIT VAE MODEL, RESHAPING THE NORMAL FINAL OUTPUT (DATASET) IS NOT POSSIBLE SO WE DO IT HERE\r\n",
    "  # WHILE IT´S STILL A TENSOR\r\n",
    "  # \r\n",
    "  #spectrogram = tf.reshape(spectrogram, [-1 ,28, 28, 1])\r\n",
    "\r\n",
    "  print(\"SPRECTROGRAM: \", spectrogram)\r\n",
    "  \r\n",
    "  return spectrogram\r\n",
    "\r\n",
    "  print(\"PREPROCESS - apply py_preprocess_audio function\")\r\n",
    "  spectrogram = tf.py_function(py_preprocess_audio, [audio], tf.float32) #apply py_process_audio function \r\n",
    "  print(\"PREPROCESS - set shape, include channel dimension\")\r\n",
    "  spectrogram.set_shape((image_target_height, image_target_width, 1)) #set shape, include channel dimension\r\n",
    "\r\n",
    "  return spectrogram#, label"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# Experimental version of above\r\n",
    "\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import tensorflow_io as tfio\r\n",
    "# Create function to load and prepare data for input \r\n",
    "# here we want to use the 9 recordings as separate features but grouped per case as input to the auto-encoder \r\n",
    "\r\n",
    "#names of 9 recordings per each case (extracted from the csv meta data file from )\r\n",
    "#names_input = ['counting-normal','counting-fast','breathing-deep','breathing-shallow','cough-heavy','cough-shallow','vowel-a','vowel-e','vowel-o']\r\n",
    "names_input = ['counting-normal']\r\n",
    "#label column from the meta data csv (#Chunk 3)\r\n",
    "name_label = 'split'\r\n",
    "image_target_height, image_target_width = 28, 28\r\n",
    "\r\n",
    "IS_VAE = True\r\n",
    "\r\n",
    "def create_input_label2(df=df_meta2,names=names_input,name_label=name_label):\r\n",
    "    input_dic = {} #Use a dictionnary to put in the 9 records per case\r\n",
    "    base_path = './CoronaHack-Respiratory-Sound-Dataset'\r\n",
    "    for index,name in enumerate(names):\r\n",
    "        print(index,name)\r\n",
    "        print(\"create path list\")\r\n",
    "        path_list = df[name].tolist()\r\n",
    "        print(path_list[:10])\r\n",
    "\r\n",
    "        path_name = []\r\n",
    "        print(\"create path name\")\r\n",
    "        for dir_name in path_list:\r\n",
    "            if dir_name is not None:\r\n",
    "                path_name.append(base_path+str(dir_name))\r\n",
    "\r\n",
    "        #path_name = base_path+str(path_list[0])\r\n",
    "        print(\"create sound tensor\")\r\n",
    "        \r\n",
    "            \r\n",
    "        sound_tensor_list = [tfio.audio.AudioIOTensor(sound_path).to_tensor()[:300000] for sound_path in path_name]\r\n",
    "        sound_rate_tensor_list = tfio.audio.AudioIOTensor(path_name[0]).rate\r\n",
    "        print(\"DIRTY\", len(sound_tensor_list))\r\n",
    "        sound_tensor_list_clean = [sound_tensor for sound_tensor in sound_tensor_list if sound_tensor.shape[0] == 300000]\r\n",
    "        print(\"CLEAN\", len(sound_tensor_list_clean))\r\n",
    "\r\n",
    "\r\n",
    "        print(\"SHAPE ME\", sound_tensor_list[0][:100000].shape)\r\n",
    "        print(\"RATE ME\", sound_rate_tensor_list)\r\n",
    "        print(\"create Sound Slices\")\r\n",
    "        sound_slices = tf.data.Dataset.from_tensor_slices(sound_tensor_list_clean)\r\n",
    "\r\n",
    "\r\n",
    "        print(\"create input dictionary\")\r\n",
    "        input_dic['x_{}'.format(index)] = sound_slices.map(lambda sample: preprocess_other(sample)) #generating the names of recordings(features x_0 till x_8) in batch mode\r\n",
    "        break\r\n",
    "       \r\n",
    "    \r\n",
    "    path_label = df[name_label]\r\n",
    "    print(path_label)\r\n",
    "    y = tf.convert_to_tensor(path_label, dtype=tf.int16)\r\n",
    "\r\n",
    "    return input_dic, y\r\n",
    "\r\n",
    "    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## #Chunk 6\r\n",
    "### test the output from function"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "x_, y = create_input_label2()\r\n",
    "x_ = list(x_.values())\r\n",
    "x_[0].batch(256)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0 counting-normal\n",
      "create path list\n",
      "['/data/train/20200413/vK2bLRNzllXNeyOMudnNSL5cfpG2/counting-normal.wav', '/data/train/20200413/bjA2KpSxneNskrLBeqi4bqoTDQl2/counting-normal.wav', '/data/train/20200413/FSzobvJqOXf0rI6X05cHqOiU9Mu2/counting-normal.wav', '/data/train/20200413/EqDWckxbsETyHUeBLQ8jLtxlhir2/counting-normal.wav', '/data/train/20200413/FGRDO4IBbAejR0WHD5YbkXTCasg2/counting-normal.wav', '/data/train/20200413/htQzROl26OWQpIYFDzv11F79PLR2/counting-normal.wav', '/data/train/20200413/pW9mCAeWYiMoM7wW7riLvNRbYDO2/counting-normal.wav', '/data/train/20200413/Eu11s84cuBTiPXTAtVf9mj3GkqA2/counting-normal.wav', '/data/train/20200413/L7S8iIPKgiO6QWLC3mGkROCMa0s1/counting-normal.wav', '/data/train/20200413/eP8gEM0KcBU6S5JpMdycX74KP3p2/counting-normal.wav']\n",
      "create path name\n",
      "create sound tensor\n",
      "DIRTY 1396\n",
      "CLEAN 1328\n",
      "SHAPE ME (100000, 1)\n",
      "RATE ME tf.Tensor(48000, shape=(), dtype=int32)\n",
      "create Sound Slices\n",
      "create input dictionary\n",
      "Start preprocessing, setting up the shape of sample\n",
      "Sample Tensor(\"args_0:0\", shape=(300000, 1), dtype=int16)\n",
      "PY-PREPROCESS set audio file as float <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "Tensor(\"Cast:0\", shape=(300000,), dtype=float32)\n",
      "PY-PREPROCESS generate the mel spectrogram\n",
      "PY-PREPROCESS devide by np.max(audio)\n",
      "SPRECTROGRAM:  Tensor(\"strided_slice_1:0\", shape=(28, 28, 1), dtype=float32)\n",
      "0       0\n",
      "1       0\n",
      "2       0\n",
      "3       0\n",
      "4       0\n",
      "       ..\n",
      "1392    0\n",
      "1393    0\n",
      "1394    1\n",
      "1395    0\n",
      "1396    0\n",
      "Name: split, Length: 1396, dtype: int32\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<BatchDataset shapes: (None, 28, 28, 1), types: tf.float32>"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## #Chunk 7\r\n",
    "### Built the auto-encoder architecture (code adapted from Tristan Class)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "from tensorflow.keras import models, layers\r\n",
    "image_target_height, image_target_width\r\n",
    "class AutoEncoder(tf.keras.Model):\r\n",
    "    \r\n",
    "    def __init__(self, latent_dim):\r\n",
    "        super().__init__()\r\n",
    "\r\n",
    "        self.latent_dim = latent_dim\r\n",
    "\r\n",
    "        # Encoder\r\n",
    "        self.encoder_reshape = layers.Reshape((image_target_height * image_target_width,)) #Shape as 64,64,1\r\n",
    "        self.encoder_fc1 = layers.Dense(32, activation=\"relu\")\r\n",
    "        self.encoder_fc2 = layers.Dense(latent_dim, activation=\"relu\")\r\n",
    "\r\n",
    "        # Decoder\r\n",
    "        self.decoder_fc1 = layers.Dense(32, activation='relu')\r\n",
    "        self.decoder_fc2 = layers.Dense(image_target_height * image_target_width, activation='sigmoid')\r\n",
    "        self.decoder_reshape = layers.Reshape((image_target_height, image_target_width,1))\r\n",
    "\r\n",
    "        self._build_graph()\r\n",
    "\r\n",
    "    def _build_graph(self):\r\n",
    "        input_shape = (image_target_height, image_target_width, 1)\r\n",
    "        self.build((None,)+ input_shape)\r\n",
    "        inputs = tf.keras.Input(shape=input_shape)\r\n",
    "        _= self.call(inputs)\r\n",
    "\r\n",
    "    def call(self, x):\r\n",
    "        z = self.encode(x)\r\n",
    "        x_new = self.decode(z)\r\n",
    "        return x_new\r\n",
    "\r\n",
    "    def encode(self, x):\r\n",
    "        x = self.encoder_reshape(x)\r\n",
    "        x = self.encoder_fc1(x)\r\n",
    "        z = self.encoder_fc2(x)\r\n",
    "        return z\r\n",
    "   \r\n",
    "\r\n",
    "    def decode(self, z):\r\n",
    "        z = self.decoder_fc1(z)\r\n",
    "        z = self.decoder_fc2(z)\r\n",
    "        x = self.decoder_reshape(z)\r\n",
    "        return x\r\n",
    "\r\n",
    "autoencoder = AutoEncoder(32)\r\n",
    "autoencoder.summary()\r\n",
    "\r\n",
    "autoencoder.compile(\r\n",
    "    optimizer='rmsprop',\r\n",
    "    loss='binary_crossentropy'\r\n",
    ")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"auto_encoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape (Reshape)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                25120     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 784)               25872     \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 53,104\n",
      "Trainable params: 53,104\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "autoencoder.summary"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<bound method Model.summary of <__main__.AutoEncoder object at 0x0000019609D97D68>>"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## #Chunk 8\r\n",
    "### Train the model\r\n",
    "\r\n",
    "Here we try to input the 9 features (recordings per case) into the model architecture"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "source": [
    "#list(x[0].as_numpy_iterator())\r\n",
    "print(x[0])\r\n",
    "print(x[0].batch(256))\r\n",
    "print(x[0].take(6))\r\n",
    "#dataset"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<MapDataset shapes: (1, 28, 28, 1), types: tf.float32>\n",
      "<BatchDataset shapes: (None, 1, 28, 28, 1), types: tf.float32>\n",
      "<TakeDataset shapes: (1, 28, 28, 1), types: tf.float32>\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "history_list = {}\r\n",
    "#dataset = tf.data.Dataset.from_tensor_slices((x[0],x[0]))\r\n",
    "dataset = tf.data.Dataset.zip((x[0],x[0]))\r\n",
    "\r\n",
    "history = autoencoder.fit(\r\n",
    "    dataset.batch(256),\r\n",
    "    epochs = 20\r\n",
    ")\r\n",
    "\r\n",
    "history_list['base'] = history"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/20\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## #Chunk 9\r\n",
    "### Variatioal Auto-Encoder Architecture"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "from tensorflow import keras\r\n",
    "from tensorflow.keras import layers\r\n",
    "\r\n",
    "class Sampling(layers.Layer):\r\n",
    "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\r\n",
    "\r\n",
    "    def call(self, inputs):\r\n",
    "        z_mean, z_log_var = inputs\r\n",
    "        batch = tf.shape(z_mean)[0]\r\n",
    "        dim = tf.shape(z_mean)[1]\r\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\r\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "latent_dim = 2\r\n",
    "\r\n",
    "encoder_inputs = keras.Input(shape=(28, 28, 1))\r\n",
    "x = layers.Conv2D(32, 3, activation=\"relu\", strides=2, padding=\"same\")(encoder_inputs)\r\n",
    "x = layers.Conv2D(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\r\n",
    "x = layers.Flatten()(x)\r\n",
    "x = layers.Dense(16, activation=\"relu\")(x)\r\n",
    "z_mean = layers.Dense(latent_dim, name=\"z_mean\")(x)\r\n",
    "z_log_var = layers.Dense(latent_dim, name=\"z_log_var\",activation=\"relu\")(x)\r\n",
    "z = Sampling()([z_mean, z_log_var])\r\n",
    "encoder = keras.Model(encoder_inputs, [z_mean, z_log_var, z], name=\"encoder\")\r\n",
    "encoder.summary()\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"encoder\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 28, 28, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 14, 14, 32)   320         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 7, 7, 64)     18496       conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 3136)         0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 16)           50192       flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "z_mean (Dense)                  (None, 2)            34          dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "z_log_var (Dense)               (None, 2)            34          dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "sampling (Sampling)             (None, 2)            0           z_mean[0][0]                     \n",
      "                                                                 z_log_var[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 69,076\n",
      "Trainable params: 69,076\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "latent_inputs = keras.Input(shape=(latent_dim,))\r\n",
    "x = layers.Dense(7 * 7 * 64, activation=\"relu\")(latent_inputs)\r\n",
    "x = layers.Reshape((7, 7, 64))(x)\r\n",
    "x = layers.Conv2DTranspose(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\r\n",
    "x = layers.Conv2DTranspose(32, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\r\n",
    "decoder_outputs = layers.Conv2DTranspose(1, 3, activation=\"sigmoid\", padding=\"same\")(x)\r\n",
    "decoder = keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\r\n",
    "decoder.summary()\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 2)]               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3136)              9408      \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose (Conv2DTran (None, 14, 14, 64)        36928     \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 28, 28, 32)        18464     \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 28, 28, 1)         289       \n",
      "=================================================================\n",
      "Total params: 65,089\n",
      "Trainable params: 65,089\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "class VAE(keras.Model):\r\n",
    "    def __init__(self, encoder, decoder, **kwargs):\r\n",
    "        super(VAE, self).__init__(**kwargs)\r\n",
    "        self.encoder = encoder\r\n",
    "        self.decoder = decoder\r\n",
    "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\r\n",
    "        self.reconstruction_loss_tracker = keras.metrics.Mean(\r\n",
    "            name=\"reconstruction_loss\"\r\n",
    "        )\r\n",
    "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\r\n",
    "\r\n",
    "    @property\r\n",
    "    def metrics(self):\r\n",
    "        return [\r\n",
    "            self.total_loss_tracker,\r\n",
    "            self.reconstruction_loss_tracker,\r\n",
    "            self.kl_loss_tracker,\r\n",
    "        ]\r\n",
    "\r\n",
    "    def train_step(self, data):\r\n",
    "        with tf.GradientTape() as tape:\r\n",
    "            z_mean, z_log_var, z = self.encoder(data)\r\n",
    "            reconstruction = self.decoder(z)\r\n",
    "            reconstruction_loss = tf.reduce_mean(\r\n",
    "                tf.reduce_sum(\r\n",
    "                    keras.losses.binary_crossentropy(data, reconstruction), axis=(1, 2)\r\n",
    "                )\r\n",
    "            )\r\n",
    "            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\r\n",
    "            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\r\n",
    "            total_loss = reconstruction_loss + kl_loss\r\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\r\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\r\n",
    "        self.total_loss_tracker.update_state(total_loss)\r\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\r\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\r\n",
    "        return {\r\n",
    "            \"loss\": self.total_loss_tracker.result(),\r\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\r\n",
    "            \"kl_loss\": self.kl_loss_tracker.result(),\r\n",
    "        }\r\n",
    "\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "vae_input = x_[0].batch(256)\r\n",
    "vae_input\r\n",
    "#vae_input.reshape(None, 28, 28, 1)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<BatchDataset shapes: (None, 28, 28, 1), types: tf.float32>"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "vae_input = x_[0].batch(5500)\r\n",
    "\r\n",
    "mymodel = VAE(encoder, decoder)\r\n",
    "mymodel.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-6))\r\n",
    "mymodel.fit(\r\n",
    "    vae_input,\r\n",
    "    epochs = 20\r\n",
    ")\r\n",
    "mymodel.summary()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/20\n",
      "1/1 [==============================] - 74s 74s/step - loss: nan - reconstruction_loss: nan - kl_loss: nan\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 59s 59s/step - loss: nan - reconstruction_loss: nan - kl_loss: nan\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 61s 61s/step - loss: nan - reconstruction_loss: nan - kl_loss: nan\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 60s 60s/step - loss: nan - reconstruction_loss: nan - kl_loss: nan\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 56s 56s/step - loss: nan - reconstruction_loss: nan - kl_loss: nan\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 46s 46s/step - loss: nan - reconstruction_loss: nan - kl_loss: nan\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 45s 45s/step - loss: nan - reconstruction_loss: nan - kl_loss: nan\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 48s 48s/step - loss: nan - reconstruction_loss: nan - kl_loss: nan\n",
      "Epoch 9/20\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-283ac61aa1d6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m mymodel.fit(\n\u001b[0;32m      6\u001b[0m     \u001b[0mvae_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m )\n\u001b[0;32m      9\u001b[0m \u001b[0mmymodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\corona\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1182\u001b[0m                 _r=1):\n\u001b[0;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1184\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1185\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\corona\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    884\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 885\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    886\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\corona\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    915\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 917\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    918\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\corona\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m   3039\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m-> 3040\u001b[1;33m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m   3041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3042\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\corona\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1962\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1963\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1964\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1966\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\corona\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 596\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    597\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\.conda\\envs\\corona\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "source": [
    "history_list = {}\r\n",
    "\r\n",
    "history = mymodel.fit(\r\n",
    "    x[0],\r\n",
    "    epochs = 20,\r\n",
    "    batch_size=32\r\n",
    "\r\n",
    ")\r\n",
    "\r\n",
    "history_list['base'] = history"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:Keras is training/fitting/evaluating on array-like data. Keras may not be optimized for this format, so if your input data format is supported by TensorFlow I/O (https://github.com/tensorflow/io) we recommend using that to load a Dataset instead.\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "in user code:\n\n    C:\\Users\\paulg\\.conda\\envs\\corona\\lib\\site-packages\\keras\\engine\\training.py:853 train_function  *\n        return step_function(self, iterator)\n    C:\\Users\\paulg\\.conda\\envs\\corona\\lib\\site-packages\\keras\\engine\\training.py:842 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\paulg\\.conda\\envs\\corona\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1286 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\paulg\\.conda\\envs\\corona\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2849 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\paulg\\.conda\\envs\\corona\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3632 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\paulg\\.conda\\envs\\corona\\lib\\site-packages\\keras\\engine\\training.py:835 run_step  **\n        outputs = model.train_step(data)\n    <ipython-input-37-3815e43f8a8f>:22 train_step\n        z_mean, z_log_var, z = self.encoder(data)\n    C:\\Users\\paulg\\.conda\\envs\\corona\\lib\\site-packages\\keras\\engine\\base_layer.py:1020 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    C:\\Users\\paulg\\.conda\\envs\\corona\\lib\\site-packages\\keras\\engine\\input_spec.py:269 assert_input_compatibility\n        ', found shape=' + display_shape(x.shape))\n\n    ValueError: Input 0 is incompatible with layer encoder: expected shape=(None, 28, 28, 1), found shape=(None, 28, 32)\n",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-103-e855be1dc087>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m )\n",
      "\u001b[1;32m~\\.conda\\envs\\corona\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1182\u001b[0m                 _r=1):\n\u001b[0;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1184\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1185\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\corona\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    884\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 885\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    886\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\corona\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    915\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 917\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    918\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\corona\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3036\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3037\u001b[0m       (graph_function,\n\u001b[1;32m-> 3038\u001b[1;33m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0m\u001b[0;32m   3039\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m   3040\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n",
      "\u001b[1;32m~\\.conda\\envs\\corona\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3458\u001b[0m               call_context_key in self._function_cache.missed):\n\u001b[0;32m   3459\u001b[0m             return self._define_function_with_shape_relaxation(\n\u001b[1;32m-> 3460\u001b[1;33m                 args, kwargs, flat_args, filtered_flat_args, cache_key_context)\n\u001b[0m\u001b[0;32m   3461\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3462\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\corona\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_define_function_with_shape_relaxation\u001b[1;34m(self, args, kwargs, flat_args, filtered_flat_args, cache_key_context)\u001b[0m\n\u001b[0;32m   3380\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3381\u001b[0m     graph_function = self._create_graph_function(\n\u001b[1;32m-> 3382\u001b[1;33m         args, kwargs, override_flat_arg_shapes=relaxed_arg_shapes)\n\u001b[0m\u001b[0;32m   3383\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marg_relaxed\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrank_only_cache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3384\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\corona\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3306\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3307\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3308\u001b[1;33m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[0;32m   3309\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3310\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\corona\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[0;32m   1005\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1006\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1007\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1008\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1009\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\corona\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    666\u001b[0m         \u001b[1;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    667\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 668\u001b[1;33m           \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    669\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    670\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\corona\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    992\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    993\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 994\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    995\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    996\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    C:\\Users\\paulg\\.conda\\envs\\corona\\lib\\site-packages\\keras\\engine\\training.py:853 train_function  *\n        return step_function(self, iterator)\n    C:\\Users\\paulg\\.conda\\envs\\corona\\lib\\site-packages\\keras\\engine\\training.py:842 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\paulg\\.conda\\envs\\corona\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1286 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\paulg\\.conda\\envs\\corona\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2849 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\paulg\\.conda\\envs\\corona\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3632 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\paulg\\.conda\\envs\\corona\\lib\\site-packages\\keras\\engine\\training.py:835 run_step  **\n        outputs = model.train_step(data)\n    <ipython-input-37-3815e43f8a8f>:22 train_step\n        z_mean, z_log_var, z = self.encoder(data)\n    C:\\Users\\paulg\\.conda\\envs\\corona\\lib\\site-packages\\keras\\engine\\base_layer.py:1020 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    C:\\Users\\paulg\\.conda\\envs\\corona\\lib\\site-packages\\keras\\engine\\input_spec.py:269 assert_input_compatibility\n        ', found shape=' + display_shape(x.shape))\n\n    ValueError: Input 0 is incompatible with layer encoder: expected shape=(None, 28, 28, 1), found shape=(None, 28, 32)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.6.13",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.13 64-bit ('corona': conda)"
  },
  "interpreter": {
   "hash": "8e06dae36da5af555d220c5b5d98ac2c0ea1251ccd3307154d7e0f059350ea4f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}