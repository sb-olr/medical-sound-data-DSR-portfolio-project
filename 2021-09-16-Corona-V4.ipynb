{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Covid Project\r\n",
    "\r\n",
    "In this data science project we want to use data from the COWAS data base (uploaded at Kaggle: https://www.kaggle.com/praveengovi/coronahack-respiratory-sound-dataset) to make a \r\n",
    "\r\n",
    "\r\n",
    "### Data Structure\r\n",
    "\r\n",
    "There are 1397 cases of which 56 are positive ones. Each case is composed of 9 independing recordings \r\n",
    "['counting-normal','counting-fast','breathing-deep','breathing-shallow','cough-heavy','cough-shallow','vowel-a','vowel-e','vowel-o']\r\n",
    "\r\n",
    "### Potential Solution\r\n",
    "\r\n",
    "Using an auto-encoder approach (out of distribution), training on \"healthy\" cases.\r\n",
    "Proposed solution (https://github.com/moiseshorta/MelSpecVAE)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## #Chunk 1\r\n",
    "### Libraries"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "\r\n",
    "#Data visualization\r\n",
    "\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "import seaborn as sns\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "\r\n",
    "#Audio Analysis\r\n",
    "import glob\r\n",
    "import IPython\r\n",
    "import librosa\r\n",
    "import librosa.display\r\n",
    "import tensorflow as tf\r\n",
    "from tensorflow import keras\r\n",
    "\r\n",
    "#path\r\n",
    "import os\r\n",
    "\r\n",
    "#"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## #Chunk 2\r\n",
    "### Import Meta data (file path information)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# import meta data\r\n",
    "# Meta data csv contain different additional information about each case.\r\n",
    "# One column contains the path to the .wav files of each case\r\n",
    "df_meta = pd.read_csv('./CoronaHack-Respiratory-Sound-Dataset/Corona-Hack-Respiratory-Sound-Metadata.csv')\r\n",
    "df_meta.info(), df_meta.shape\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1397 entries, 0 to 1396\n",
      "Data columns (total 37 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   USER_ID                 1397 non-null   object \n",
      " 1   COUNTRY                 1397 non-null   object \n",
      " 2   AGE                     1397 non-null   int64  \n",
      " 3   COVID_STATUS            1396 non-null   object \n",
      " 4   ENGLISH_PROFICIENCY     1397 non-null   object \n",
      " 5   GENDER                  1397 non-null   object \n",
      " 6   COUNTY_RO_STATE         1397 non-null   object \n",
      " 7   CITY_LOCALITY           1228 non-null   object \n",
      " 8   Diabetes                1397 non-null   int64  \n",
      " 9   Asthma                  1397 non-null   int64  \n",
      " 10  Smoker                  1397 non-null   int64  \n",
      " 11  Hypertension            1397 non-null   int64  \n",
      " 12  Fever                   1397 non-null   int64  \n",
      " 13  Returning_User          1397 non-null   int64  \n",
      " 14  Using_Mask              1397 non-null   int64  \n",
      " 15  Cold                    1397 non-null   int64  \n",
      " 16  Caugh                   1397 non-null   int64  \n",
      " 17  Muscle_Pain             1397 non-null   int64  \n",
      " 18  loss_of_smell           1397 non-null   int64  \n",
      " 19  Sore_Throat             1397 non-null   int64  \n",
      " 20  Fatigue                 1397 non-null   int64  \n",
      " 21  Breathing_Difficulties  1397 non-null   int64  \n",
      " 22  Chronic_Lung_Disease    1397 non-null   int64  \n",
      " 23  Ischemic_Heart_Disease  1397 non-null   int64  \n",
      " 24  Pneumonia               1397 non-null   int64  \n",
      " 25  COVID_test_status       1355 non-null   float64\n",
      " 26  Diarrheoa               1397 non-null   int64  \n",
      " 27  DATES                   1397 non-null   int64  \n",
      " 28  breathing-deep          1396 non-null   object \n",
      " 29  breathing-shallow       1396 non-null   object \n",
      " 30  cough-heavy             1396 non-null   object \n",
      " 31  cough-shallow           1395 non-null   object \n",
      " 32  counting-fast           1397 non-null   object \n",
      " 33  counting-normal         1397 non-null   object \n",
      " 34  vowel-a                 1396 non-null   object \n",
      " 35  vowel-e                 1396 non-null   object \n",
      " 36  vowel-o                 1395 non-null   object \n",
      "dtypes: float64(1), int64(20), object(16)\n",
      "memory usage: 403.9+ KB\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(None, (1397, 37))"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## #Chunk 3\r\n",
    "### Get the label for each case"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "#Get the label (healthy / COVID) \r\n",
    "\r\n",
    "#split COVID STATUS column to get labels in column 'split'\r\n",
    "df_meta['split'] = df_meta['COVID_STATUS'].str.split('_').str.get(0)\r\n",
    "#Check for NA\r\n",
    "df_meta.loc[:,'counting-normal'].isna().sum()\r\n",
    "df_meta.loc[:,'split'].value_counts()\r\n",
    "\r\n",
    "#Generate a dict to re-categorize the split column\r\n",
    "cat_dict = {'healthy':0,'no':0,'resp':0,'recovered':0,'positive':1}\r\n",
    "\r\n",
    "#map cat_dict to split column \r\n",
    "df_meta.loc[:,'split'] =  df_meta.loc[:,'split'].map(cat_dict)\r\n",
    "df_meta2 = df_meta.dropna(subset=['split'])\r\n",
    "df_meta2.loc[:,'split'] = df_meta2.loc[:,'split'].astype('int32')\r\n",
    "\r\n",
    "\r\n",
    "#Extract positive USER ID\r\n",
    "df_meta_positives = df_meta[df_meta['split'] == 1]\r\n",
    "df_meta_negatives = df_meta[df_meta['split'] == 0]\r\n",
    "\r\n",
    "positives = list(df_meta_positives['USER_ID'])\r\n",
    "negatives = list(df_meta_negatives['USER_ID'])\r\n",
    "len(positives),len(negatives)\r\n",
    "#positives"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\paulg\\.conda\\envs\\corona\\lib\\site-packages\\pandas\\core\\indexing.py:1745: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(ilocs[0], value)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(56, 1340)"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## #Chunk 5\r\n",
    "### generate Function to create the input data for auto-encoder"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "# Create function to load and prepare data for input \r\n",
    "# here we want to use the 9 recordings as separate features but grouped per case as input to the auto-encoder \r\n",
    "\r\n",
    "#names of 9 recordings per each case (extracted from the csv meta data file from )\r\n",
    "names_input = ['counting-normal','counting-fast','breathing-deep','breathing-shallow','cough-heavy','cough-shallow','vowel-a','vowel-e','vowel-o']\r\n",
    "#label column from the meta data csv (#Chunk 3)\r\n",
    "name_label = 'split'\r\n",
    "\r\n",
    "def create_input_label(df=df_meta2,names=names_input,name_label=name_label):\r\n",
    "    input_dic = {} #Use a dictionnary to put in the 9 records per case\r\n",
    "    base_path = './CoronaHack-Respiratory-Sound-Dataset'\r\n",
    "    \r\n",
    "    for index,name in enumerate(names):\r\n",
    "        #print(index,name)\r\n",
    "        print(\"Create input run\")\r\n",
    "        path_list = df[name].tolist()\r\n",
    "        print(path_list[:10])\r\n",
    "        path_name = []\r\n",
    "        for dir_name in path_list:\r\n",
    "            path_name.append(base_path+str(dir_name))\r\n",
    "\r\n",
    "        print(path_name[:10])\r\n",
    "        print(\"Sound paths convert to tensor\")\r\n",
    "        sound_paths_tensor = tf.convert_to_tensor(path_name, dtype=tf.string) #convert to tensor\r\n",
    "\r\n",
    "        print(\"Sound PATH\", sound_paths_tensor[0])\r\n",
    "        print(\"Sound Dataset from tensor slices\")\r\n",
    "        sound = tf.data.Dataset.from_tensor_slices(sound_paths_tensor)\r\n",
    "        print(\"Sound PATH from slices\", sound[0])\r\n",
    "        #sound = tf.data.Dataset.from_generator(lambda sample: preprocess_other(sample).batch(32), output_types=tf.int32, output_shapes = (64,64,1),)\r\n",
    "        print(\"Calling preprocessing\")\r\n",
    "        print(\"SOUNDD\", sound)\r\n",
    "        input_dic['x_{}'.format(index)] = sound.map(lambda sample: preprocess_other(sample)) #generating the names of recordings(features x_0 till x_8) in batch mode\r\n",
    "\r\n",
    "\r\n",
    "    path_label = df[name_label]\r\n",
    "    #print(path_label)\r\n",
    "    y = tf.convert_to_tensor(path_label, dtype=tf.int16)\r\n",
    "\r\n",
    "    return input_dic,y\r\n",
    "\r\n",
    "    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "x,y = create_input_label()\r\n",
    "x = list(x.values())\r\n",
    "x"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Create input run\n",
      "['/data/train/20200413/vK2bLRNzllXNeyOMudnNSL5cfpG2/counting-normal.wav', '/data/train/20200413/bjA2KpSxneNskrLBeqi4bqoTDQl2/counting-normal.wav', '/data/train/20200413/FSzobvJqOXf0rI6X05cHqOiU9Mu2/counting-normal.wav', '/data/train/20200413/EqDWckxbsETyHUeBLQ8jLtxlhir2/counting-normal.wav', '/data/train/20200413/FGRDO4IBbAejR0WHD5YbkXTCasg2/counting-normal.wav', '/data/train/20200413/htQzROl26OWQpIYFDzv11F79PLR2/counting-normal.wav', '/data/train/20200413/pW9mCAeWYiMoM7wW7riLvNRbYDO2/counting-normal.wav', '/data/train/20200413/Eu11s84cuBTiPXTAtVf9mj3GkqA2/counting-normal.wav', '/data/train/20200413/L7S8iIPKgiO6QWLC3mGkROCMa0s1/counting-normal.wav', '/data/train/20200413/eP8gEM0KcBU6S5JpMdycX74KP3p2/counting-normal.wav']\n",
      "['./CoronaHack-Respiratory-Sound-Dataset/data/train/20200413/vK2bLRNzllXNeyOMudnNSL5cfpG2/counting-normal.wav', './CoronaHack-Respiratory-Sound-Dataset/data/train/20200413/bjA2KpSxneNskrLBeqi4bqoTDQl2/counting-normal.wav', './CoronaHack-Respiratory-Sound-Dataset/data/train/20200413/FSzobvJqOXf0rI6X05cHqOiU9Mu2/counting-normal.wav', './CoronaHack-Respiratory-Sound-Dataset/data/train/20200413/EqDWckxbsETyHUeBLQ8jLtxlhir2/counting-normal.wav', './CoronaHack-Respiratory-Sound-Dataset/data/train/20200413/FGRDO4IBbAejR0WHD5YbkXTCasg2/counting-normal.wav', './CoronaHack-Respiratory-Sound-Dataset/data/train/20200413/htQzROl26OWQpIYFDzv11F79PLR2/counting-normal.wav', './CoronaHack-Respiratory-Sound-Dataset/data/train/20200413/pW9mCAeWYiMoM7wW7riLvNRbYDO2/counting-normal.wav', './CoronaHack-Respiratory-Sound-Dataset/data/train/20200413/Eu11s84cuBTiPXTAtVf9mj3GkqA2/counting-normal.wav', './CoronaHack-Respiratory-Sound-Dataset/data/train/20200413/L7S8iIPKgiO6QWLC3mGkROCMa0s1/counting-normal.wav', './CoronaHack-Respiratory-Sound-Dataset/data/train/20200413/eP8gEM0KcBU6S5JpMdycX74KP3p2/counting-normal.wav']\n",
      "Sound paths convert to tensor\n",
      "Sound PATH tf.Tensor(b'./CoronaHack-Respiratory-Sound-Dataset/data/train/20200413/vK2bLRNzllXNeyOMudnNSL5cfpG2/counting-normal.wav', shape=(), dtype=string)\n",
      "Sound Dataset from tensor slices\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "'TensorSliceDataset' object does not support indexing",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-9571fd0bf905>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_input_label\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-18-b57baf825f4a>\u001b[0m in \u001b[0;36mcreate_input_label\u001b[1;34m(df, names, name_label)\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Sound Dataset from tensor slices\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[0msound\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_tensor_slices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msound_paths_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Sound PATH from slices\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msound\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m         \u001b[1;31m#sound = tf.data.Dataset.from_generator(lambda sample: preprocess_other(sample).batch(32), output_types=tf.int32, output_shapes = (64,64,1),)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Calling preprocessing\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'TensorSliceDataset' object does not support indexing"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## #Chunk 4\r\n",
    "### Define Function for .wav import and preprocessing "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "source": [
    "# Write function for import and preprocessing of all 9 .wav files per case (code adapted from Tristan classes) \r\n",
    "\r\n",
    "import cv2\r\n",
    "def preprocess_other(sample):\r\n",
    "  print(\"Start preprocessing, setting up the shape of sample\")\r\n",
    "  print(\"Sample\", sample)\r\n",
    "  \r\n",
    "  audio = sample\r\n",
    "  #label = sample['label']\r\n",
    "  audio = tf.reshape(sample, [-1])\r\n",
    "        \r\n",
    "  \r\n",
    "  print(\"PY-PREPROCESS set audio file as float\", type(audio))\r\n",
    "  audio = tf.cast(audio, tf.float32) #set audio file as float\r\n",
    "  #audio = audio[24500:5000+len(audio)//10]\r\n",
    "  # Plot audio amplitude\r\n",
    "  # plt.figure(figsize=(10,15))\r\n",
    "  # plt.plot(audio)\r\n",
    "  # plt.show()\r\n",
    "  # plt.close()\r\n",
    "  \r\n",
    "  print(audio)\r\n",
    "  print(\"PY-PREPROCESS generate the mel spectrogram\")\r\n",
    "  #generate the mel spectrogram\r\n",
    "  spectrogram = tfio.audio.spectrogram( \r\n",
    "      audio, nfft=1024, window=1024, stride=64\r\n",
    "  )\r\n",
    "\r\n",
    "  spectrogram = tfio.audio.melscale(\r\n",
    "      spectrogram, rate=8000, mels=64, fmin=0, fmax=2000 #mels = bins, fmin,fmax = frequences\r\n",
    "  )\r\n",
    "\r\n",
    "  print(\"PY-PREPROCESS devide by np.max(audio)\")\r\n",
    "  spectrogram /= tf.math.reduce_max(spectrogram) #normalization\r\n",
    "  spectrogram = tf.expand_dims(spectrogram, axis=-1) #add dimension 2D -> 3D\r\n",
    "  spectrogram = tf.image.resize(spectrogram, (image_target_height, image_target_height)) #resize in two dimensions\r\n",
    "  spectrogram = tf.transpose(spectrogram, perm=(1,0,2)) #transpose the first two axis\r\n",
    "  spectrogram = spectrogram[::-1, :, :] #flip the first axis(frequency)\r\n",
    "\r\n",
    "  # plt.figure(figsize=(10,15))\r\n",
    "  # plt.imshow(spectrogram[::-1,:], cmap='inferno') #flipping upside down\r\n",
    "  # plt.show()\r\n",
    "  # plt.close()\r\n",
    "  \r\n",
    "  print(spectrogram)\r\n",
    "  return spectrogram\r\n",
    "\r\n",
    "  print(\"PREPROCESS - apply py_preprocess_audio function\")\r\n",
    "  spectrogram = tf.py_function(py_preprocess_audio, [audio], tf.float32) #apply py_process_audio function \r\n",
    "  print(\"PREPROCESS - set shape, include channel dimension\")\r\n",
    "  spectrogram.set_shape((image_target_height, image_target_width, 1)) #set shape, include channel dimension\r\n",
    "\r\n",
    "  return spectrogram#, label"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "source": [
    "# Experimental version of above\r\n",
    "\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import tensorflow_io as tfio\r\n",
    "# Create function to load and prepare data for input \r\n",
    "# here we want to use the 9 recordings as separate features but grouped per case as input to the auto-encoder \r\n",
    "\r\n",
    "#names of 9 recordings per each case (extracted from the csv meta data file from )\r\n",
    "# names_input = ['counting-normal','counting-fast','breathing-deep','breathing-shallow','cough-heavy','cough-shallow','vowel-a','vowel-e','vowel-o']\r\n",
    "names_input = ['counting-normal']\r\n",
    "#label column from the meta data csv (#Chunk 3)\r\n",
    "name_label = 'split'\r\n",
    "image_target_height, image_target_width = 28, 28\r\n",
    "\r\n",
    "def create_input_label2(df=df_meta2,names=names_input,name_label=name_label):\r\n",
    "    input_dic = {} #Use a dictionnary to put in the 9 records per case\r\n",
    "    base_path = './CoronaHack-Respiratory-Sound-Dataset'\r\n",
    "    for index,name in enumerate(names):\r\n",
    "        print(index,name)\r\n",
    "        print(\"create path list\")\r\n",
    "        path_list = df[name].tolist()\r\n",
    "        print(path_list[:10])\r\n",
    "\r\n",
    "        path_name = []\r\n",
    "        print(\"create path name\")\r\n",
    "        for dir_name in path_list:\r\n",
    "            if dir_name is not None:\r\n",
    "                path_name.append(base_path+str(dir_name))\r\n",
    "\r\n",
    "        #path_name = base_path+str(path_list[0])\r\n",
    "        print(\"create sound tensor\")\r\n",
    "        sound_tensor_list = [tfio.audio.AudioIOTensor(sound_path).to_tensor()[:300000] for sound_path in path_name]\r\n",
    "        sound_rate_tensor_list = tfio.audio.AudioIOTensor(path_name[0]).rate\r\n",
    "        print(\"DIRTY\", len(sound_tensor_list))\r\n",
    "        sound_tensor_list_clean = [sound_tensor for sound_tensor in sound_tensor_list if sound_tensor.shape[0] == 300000]\r\n",
    "        print(\"CLEAN\", len(sound_tensor_list_clean))\r\n",
    "\r\n",
    "\r\n",
    "        print(\"SHAPE ME\", sound_tensor_list[0][:100000].shape)\r\n",
    "        print(\"RATE ME\", sound_rate_tensor_list)\r\n",
    "        print(\"create Sound Slices\")\r\n",
    "        sound_slices = tf.data.Dataset.from_tensor_slices(sound_tensor_list_clean)\r\n",
    "\r\n",
    "\r\n",
    "        print(\"create input dictionary\")\r\n",
    "        input_dic['x_{}'.format(index)] = sound_slices.map(lambda sample: preprocess_other(sample)) #generating the names of recordings(features x_0 till x_8) in batch mode\r\n",
    "        \r\n",
    "    \r\n",
    "    path_label = df[name_label]\r\n",
    "    print(path_label)\r\n",
    "    y = tf.convert_to_tensor(path_label, dtype=tf.int16)\r\n",
    "\r\n",
    "    return input_dic, y\r\n",
    "\r\n",
    "    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## #Chunk 6\r\n",
    "### test the output from function"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "source": [
    "x, y = create_input_label2()\r\n",
    "x = list(x.values())\r\n",
    "x"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0 counting-normal\n",
      "create path list\n",
      "['/data/train/20200413/vK2bLRNzllXNeyOMudnNSL5cfpG2/counting-normal.wav', '/data/train/20200413/bjA2KpSxneNskrLBeqi4bqoTDQl2/counting-normal.wav', '/data/train/20200413/FSzobvJqOXf0rI6X05cHqOiU9Mu2/counting-normal.wav', '/data/train/20200413/EqDWckxbsETyHUeBLQ8jLtxlhir2/counting-normal.wav', '/data/train/20200413/FGRDO4IBbAejR0WHD5YbkXTCasg2/counting-normal.wav', '/data/train/20200413/htQzROl26OWQpIYFDzv11F79PLR2/counting-normal.wav', '/data/train/20200413/pW9mCAeWYiMoM7wW7riLvNRbYDO2/counting-normal.wav', '/data/train/20200413/Eu11s84cuBTiPXTAtVf9mj3GkqA2/counting-normal.wav', '/data/train/20200413/L7S8iIPKgiO6QWLC3mGkROCMa0s1/counting-normal.wav', '/data/train/20200413/eP8gEM0KcBU6S5JpMdycX74KP3p2/counting-normal.wav']\n",
      "create path name\n",
      "create sound tensor\n",
      "DIRTY 1396\n",
      "CLEAN 1328\n",
      "SHAPE ME (100000, 1)\n",
      "RATE ME tf.Tensor(48000, shape=(), dtype=int32)\n",
      "create Sound Slices\n",
      "create input dictionary\n",
      "Start preprocessing, setting up the shape of sample\n",
      "Sample Tensor(\"args_0:0\", shape=(300000, 1), dtype=int16)\n",
      "PY-PREPROCESS set audio file as float <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "Tensor(\"Cast:0\", shape=(300000,), dtype=float32)\n",
      "PY-PREPROCESS generate the mel spectrogram\n",
      "PY-PREPROCESS devide by np.max(audio)\n",
      "Tensor(\"strided_slice_1:0\", shape=(28, 28, 1), dtype=float32)\n",
      "0       0\n",
      "1       0\n",
      "2       0\n",
      "3       0\n",
      "4       0\n",
      "       ..\n",
      "1392    0\n",
      "1393    0\n",
      "1394    1\n",
      "1395    0\n",
      "1396    0\n",
      "Name: split, Length: 1396, dtype: int32\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[<MapDataset shapes: (28, 28, 1), types: tf.float32>]"
      ]
     },
     "metadata": {},
     "execution_count": 89
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## #Chunk 7\r\n",
    "### Built the auto-encoder architecture (code adapted from Tristan Class)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "source": [
    "from tensorflow.keras import models, layers\r\n",
    "image_target_height, image_target_width\r\n",
    "class AutoEncoder(tf.keras.Model):\r\n",
    "    \r\n",
    "    def __init__(self, latent_dim):\r\n",
    "        super().__init__()\r\n",
    "\r\n",
    "        self.latent_dim = latent_dim\r\n",
    "\r\n",
    "        # Encoder\r\n",
    "        self.encoder_reshape = layers.Reshape((image_target_height * image_target_width,)) #Shape as 64,64,1\r\n",
    "        self.encoder_fc1 = layers.Dense(32, activation=\"relu\")\r\n",
    "        self.encoder_fc2 = layers.Dense(latent_dim, activation=\"relu\")\r\n",
    "\r\n",
    "        # Decoder\r\n",
    "        self.decoder_fc1 = layers.Dense(32, activation='relu')\r\n",
    "        self.decoder_fc2 = layers.Dense(image_target_height * image_target_width, activation='sigmoid')\r\n",
    "        self.decoder_reshape = layers.Reshape((image_target_height, image_target_width,1))\r\n",
    "\r\n",
    "        self._build_graph()\r\n",
    "\r\n",
    "    def _build_graph(self):\r\n",
    "        input_shape = (image_target_height, image_target_width, 1)\r\n",
    "        self.build((None,)+ input_shape)\r\n",
    "        inputs = tf.keras.Input(shape=input_shape)\r\n",
    "        _= self.call(inputs)\r\n",
    "\r\n",
    "    def call(self, x):\r\n",
    "        z = self.encode(x)\r\n",
    "        x_new = self.decode(z)\r\n",
    "        return x_new\r\n",
    "\r\n",
    "    def encode(self, x):\r\n",
    "        x = self.encoder_reshape(x)\r\n",
    "        x = self.encoder_fc1(x)\r\n",
    "        z = self.encoder_fc2(x)\r\n",
    "        return z\r\n",
    "   \r\n",
    "\r\n",
    "    def decode(self, z):\r\n",
    "        z = self.decoder_fc1(z)\r\n",
    "        z = self.decoder_fc2(z)\r\n",
    "        x = self.decoder_reshape(z)\r\n",
    "        return x\r\n",
    "\r\n",
    "autoencoder = AutoEncoder(32)\r\n",
    "autoencoder.summary()\r\n",
    "\r\n",
    "autoencoder.compile(\r\n",
    "    optimizer='rmsprop',\r\n",
    "    loss='binary_crossentropy'\r\n",
    ")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"auto_encoder_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape_12 (Reshape)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 32)                25120     \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 784)               25872     \n",
      "_________________________________________________________________\n",
      "reshape_13 (Reshape)         (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 53,104\n",
      "Trainable params: 53,104\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## #Chunk 8\r\n",
    "### Train the model\r\n",
    "\r\n",
    "Here we try to input the 9 features (recordings per case) into the model architecture"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "source": [
    "#list(x[0].as_numpy_iterator())\r\n",
    "print(x[0])\r\n",
    "print(x[0].batch(256))\r\n",
    "print(x[0].take(6))\r\n",
    "dataset"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<MapDataset shapes: (64, 64, 1), types: tf.float32>\n",
      "<BatchDataset shapes: (None, 64, 64, 1), types: tf.float32>\n",
      "<TakeDataset shapes: (64, 64, 1), types: tf.float32>\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<ZipDataset shapes: ((64, 64, 1), (64, 64, 1)), types: (tf.float32, tf.float32)>"
      ]
     },
     "metadata": {},
     "execution_count": 76
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "source": [
    "history_list = {}\r\n",
    "#dataset = tf.data.Dataset.from_tensor_slices((x[0],x[0]))\r\n",
    "dataset = tf.data.Dataset.zip((x[0],x[0]))\r\n",
    "\r\n",
    "history = autoencoder.fit(\r\n",
    "    dataset.batch(256),\r\n",
    "    epochs = 20\r\n",
    ")\r\n",
    "\r\n",
    "history_list['base'] = history"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/20\n",
      "6/6 [==============================] - 156s 24s/step - loss: nan\n",
      "Epoch 2/20\n",
      "6/6 [==============================] - 146s 23s/step - loss: nan\n",
      "Epoch 3/20\n",
      "4/6 [===================>..........] - ETA: 55s - loss: nan "
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-91-ef3e8ea59f5d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m history = autoencoder.fit(\n\u001b[0;32m      6\u001b[0m     \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m256\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m )\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\corona\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1182\u001b[0m                 _r=1):\n\u001b[0;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1184\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1185\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\corona\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    884\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 885\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    886\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\corona\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    915\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 917\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    918\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\corona\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m   3039\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m-> 3040\u001b[1;33m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m   3041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3042\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\corona\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1962\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1963\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1964\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1966\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\corona\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 596\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    597\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\.conda\\envs\\corona\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## #Chunk 9\r\n",
    "### Test with one feature"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    " x[0]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<BatchDataset shapes: (None, 64, 64, 1), types: tf.float32>"
      ]
     },
     "metadata": {},
     "execution_count": 188
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "history_list = {}\r\n",
    "\r\n",
    "history = autoencoder.fit(\r\n",
    "    x[0],\r\n",
    "    epochs = 20,\r\n",
    "    batch_size=32\r\n",
    "\r\n",
    ")\r\n",
    "\r\n",
    "history_list['base'] = history"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "in user code:\n\n    C:\\Users\\paulg\\.conda\\envs\\corona\\lib\\site-packages\\keras\\engine\\training.py:853 train_function  *\n        return step_function(self, iterator)\n    C:\\Users\\paulg\\.conda\\envs\\corona\\lib\\site-packages\\keras\\engine\\training.py:842 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\paulg\\.conda\\envs\\corona\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1286 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\paulg\\.conda\\envs\\corona\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2849 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\paulg\\.conda\\envs\\corona\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3632 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\paulg\\.conda\\envs\\corona\\lib\\site-packages\\keras\\engine\\training.py:835 run_step  **\n        outputs = model.train_step(data)\n    C:\\Users\\paulg\\.conda\\envs\\corona\\lib\\site-packages\\keras\\engine\\training.py:791 train_step\n        self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    C:\\Users\\paulg\\.conda\\envs\\corona\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:522 minimize\n        return self.apply_gradients(grads_and_vars, name=name)\n    C:\\Users\\paulg\\.conda\\envs\\corona\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:622 apply_gradients\n        grads_and_vars = optimizer_utils.filter_empty_gradients(grads_and_vars)\n    C:\\Users\\paulg\\.conda\\envs\\corona\\lib\\site-packages\\keras\\optimizer_v2\\utils.py:73 filter_empty_gradients\n        ([v.name for _, v in grads_and_vars],))\n\n    ValueError: No gradients provided for any variable: ['dense_8/kernel:0', 'dense_8/bias:0', 'dense_9/kernel:0', 'dense_9/bias:0', 'dense_10/kernel:0', 'dense_10/bias:0', 'dense_11/kernel:0', 'dense_11/bias:0'].\n",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-189-49983f3596b7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m )\n",
      "\u001b[1;32m~\\.conda\\envs\\corona\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1182\u001b[0m                 _r=1):\n\u001b[0;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1184\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1185\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\corona\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    884\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 885\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    886\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\corona\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    915\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 917\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    918\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\corona\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3036\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3037\u001b[0m       (graph_function,\n\u001b[1;32m-> 3038\u001b[1;33m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0m\u001b[0;32m   3039\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m   3040\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n",
      "\u001b[1;32m~\\.conda\\envs\\corona\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3458\u001b[0m               call_context_key in self._function_cache.missed):\n\u001b[0;32m   3459\u001b[0m             return self._define_function_with_shape_relaxation(\n\u001b[1;32m-> 3460\u001b[1;33m                 args, kwargs, flat_args, filtered_flat_args, cache_key_context)\n\u001b[0m\u001b[0;32m   3461\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3462\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\corona\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_define_function_with_shape_relaxation\u001b[1;34m(self, args, kwargs, flat_args, filtered_flat_args, cache_key_context)\u001b[0m\n\u001b[0;32m   3380\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3381\u001b[0m     graph_function = self._create_graph_function(\n\u001b[1;32m-> 3382\u001b[1;33m         args, kwargs, override_flat_arg_shapes=relaxed_arg_shapes)\n\u001b[0m\u001b[0;32m   3383\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marg_relaxed\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrank_only_cache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3384\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\corona\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3306\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3307\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3308\u001b[1;33m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[0;32m   3309\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3310\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\corona\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[0;32m   1005\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1006\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1007\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1008\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1009\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\corona\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    666\u001b[0m         \u001b[1;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    667\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 668\u001b[1;33m           \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    669\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    670\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\corona\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    992\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    993\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 994\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    995\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    996\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    C:\\Users\\paulg\\.conda\\envs\\corona\\lib\\site-packages\\keras\\engine\\training.py:853 train_function  *\n        return step_function(self, iterator)\n    C:\\Users\\paulg\\.conda\\envs\\corona\\lib\\site-packages\\keras\\engine\\training.py:842 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\paulg\\.conda\\envs\\corona\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1286 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\paulg\\.conda\\envs\\corona\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2849 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\paulg\\.conda\\envs\\corona\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3632 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\paulg\\.conda\\envs\\corona\\lib\\site-packages\\keras\\engine\\training.py:835 run_step  **\n        outputs = model.train_step(data)\n    C:\\Users\\paulg\\.conda\\envs\\corona\\lib\\site-packages\\keras\\engine\\training.py:791 train_step\n        self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    C:\\Users\\paulg\\.conda\\envs\\corona\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:522 minimize\n        return self.apply_gradients(grads_and_vars, name=name)\n    C:\\Users\\paulg\\.conda\\envs\\corona\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:622 apply_gradients\n        grads_and_vars = optimizer_utils.filter_empty_gradients(grads_and_vars)\n    C:\\Users\\paulg\\.conda\\envs\\corona\\lib\\site-packages\\keras\\optimizer_v2\\utils.py:73 filter_empty_gradients\n        ([v.name for _, v in grads_and_vars],))\n\n    ValueError: No gradients provided for any variable: ['dense_8/kernel:0', 'dense_8/bias:0', 'dense_9/kernel:0', 'dense_9/bias:0', 'dense_10/kernel:0', 'dense_10/bias:0', 'dense_11/kernel:0', 'dense_11/bias:0'].\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.6.13",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.13 64-bit ('corona': conda)"
  },
  "interpreter": {
   "hash": "8e06dae36da5af555d220c5b5d98ac2c0ea1251ccd3307154d7e0f059350ea4f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}